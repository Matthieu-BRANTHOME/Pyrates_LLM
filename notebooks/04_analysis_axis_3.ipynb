{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "![Logo Pyrates LLM](../assets/pyratesllm_logo_500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# **Notebook#04 : Analysis on axis 3**\n",
    "## [Evaluation of feedback content]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1/ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import students_constants as stu_const\n",
    "import interaction_constants as int_const\n",
    "import tests_constants  as tes_const\n",
    "import session_date_constants as ses_const\n",
    "\n",
    "# External\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2/ Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data = pd.read_pickle(\"../data/interim/interaction_data.pkl\")\n",
    "pre_test_data = pd.read_pickle(\"../data/interim/pre_test_data.pkl\")\n",
    "post_test_data = pd.read_pickle(\"../data/interim/post_test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3/ Students' Perception of assistant helps (Q3.1) [B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "What is student perception of the assistant helps depending of groups ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of questions to analyze (from _QA to _QE)\n",
    "question_cols = tes_const.ASSISTANT_NUM_QUESTIONS\n",
    "\n",
    "# Mapping of question keys to plain text question\n",
    "QUESTION_MAPPING = {\n",
    "    tes_const.QA_KEY: \"Did you find the assistant help useful to progress in the game?\",\n",
    "    tes_const.QB_KEY: \"Did you find the assistant help useful to learn Python programming?\",\n",
    "    tes_const.QC_KEY: \"Would you like to have more help from a digital assistant in the future?\",\n",
    "    tes_const.QD_KEY: \"Did you find the assistant help easy to understand?\",\n",
    "    tes_const.QE_KEY: \"Did you find that the assistant help was correct (without errors)?\"\n",
    "}\n",
    "\n",
    "group_col=tes_const.GROUP_ID_KEY\n",
    "# Filter only groups B and C\n",
    "df_filtered = post_test_data[post_test_data[group_col].isin([tes_const.GROUP_B, tes_const.GROUP_C])].copy()\n",
    "\n",
    "# Dictionary to store results\n",
    "stats_dict = {}\n",
    "\n",
    "# Loop over each question\n",
    "for q in question_cols:\n",
    "    # Get data for both groups\n",
    "    calls_B = df_filtered[df_filtered[group_col] == tes_const.GROUP_B][q].dropna()\n",
    "    calls_C = df_filtered[df_filtered[group_col] == tes_const.GROUP_C][q].dropna()\n",
    "    \n",
    "    # Descriptive statistics\n",
    "    mean_B, std_B = calls_B.mean(), calls_B.std()\n",
    "    mean_C, std_C = calls_C.mean(), calls_C.std()\n",
    "    n_B, n_C = len(calls_B), len(calls_C)\n",
    "    \n",
    "    print(f\"\\n######## {q} : {QUESTION_MAPPING[q]} ########\")\n",
    "    print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "    print(f\"Group B (n={n_B}): M = {mean_B:.2f}, SD = {std_B:.2f}\")\n",
    "    print(f\"Group C (n={n_C}): M = {mean_C:.2f}, SD = {std_C:.2f}\")\n",
    "    \n",
    "    # Normality tests (Shapiro-Wilk)\n",
    "    shapiro_B = stats.shapiro(calls_B) if n_B >= 3 else None\n",
    "    shapiro_C = stats.shapiro(calls_C) if n_C >= 3 else None\n",
    "    \n",
    "    # TODO WARNING : alpha is temporary set here to 0.06 because some results are almost signifiant\n",
    "    alpha = 0.06\n",
    "    print(\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "    if shapiro_B and shapiro_C:\n",
    "        print(f\"Group B: p-value = {shapiro_B.pvalue:.4f} -> {'normally distributed' if shapiro_B.pvalue >= alpha else 'not normally distributed'}\")\n",
    "        print(f\"Group C: p-value = {shapiro_C.pvalue:.4f} -> {'normally distributed' if shapiro_C.pvalue >= alpha else 'not normally distributed'}\")\n",
    "        normal_B, normal_C = shapiro_B.pvalue >= alpha, shapiro_C.pvalue >= alpha\n",
    "    else:\n",
    "        # Not enough data for Shapiro test\n",
    "        print(\"Not enough data for Shapiro-Wilk test\")\n",
    "        normal_B, normal_C = False, False\n",
    "    \n",
    "    # Levene test for equal variances\n",
    "    if n_B > 1 and n_C > 1:\n",
    "        levene_p = stats.levene(calls_B, calls_C).pvalue\n",
    "        equal_var = levene_p >= alpha\n",
    "        print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "        print(f\"Levene p-value = {levene_p:.4f} -> {'variances are similar' if equal_var else 'variances differ'}\")\n",
    "    else:\n",
    "        equal_var = False\n",
    "        print(\"\\nNot enough data for Levene test\")\n",
    "    \n",
    "    # Choose statistical test\n",
    "    print(f\"\\n=== STATISTICAL TEST ===\")\n",
    "    if normal_B and normal_C and equal_var:\n",
    "        print(\"Using independent t-test (parametric)\")\n",
    "        stat, p_value = stats.ttest_ind(calls_B, calls_C, equal_var=True)\n",
    "        # Cohen's d\n",
    "        pooled_std = np.sqrt(((n_B - 1)*std_B**2 + (n_C - 1)*std_C**2) / (n_B + n_C - 2))\n",
    "        effect_size = (mean_B - mean_C) / pooled_std\n",
    "        effect_type = \"Cohen's d\"\n",
    "\n",
    "    else:\n",
    "        print(\"Using Mann-Whitney U test (non-parametric)\")\n",
    "        stat, p_value = stats.mannwhitneyu(calls_B, calls_C, alternative='two-sided')\n",
    "        # Effect size r = Z / sqrt(N)\n",
    "        n_total = n_B + n_C\n",
    "        z_score = stats.norm.ppf(1 - p_value/2)  # convert two-sided p-value to Z\n",
    "        effect_size = abs(z_score) / np.sqrt(n_total)\n",
    "        effect_type = \"r\"\n",
    "\n",
    "    print(f\"Test statistic = {stat:.4f}\")\n",
    "    print(f\"P-value = {p_value:.4f}\")\n",
    "    print(f\"Effect size ({effect_type}) = {effect_size:.4f}\")\n",
    "    \n",
    "    # Interpret effect size\n",
    "    if effect_type == \"Cohen's d\":\n",
    "        if abs(effect_size) < 0.2:\n",
    "            label = \"negligible\"\n",
    "        elif abs(effect_size) < 0.5:\n",
    "            label = \"small\"\n",
    "        elif abs(effect_size) < 0.8:\n",
    "            label = \"medium\"\n",
    "        else:\n",
    "            label = \"large\"\n",
    "    else:  # r\n",
    "        if effect_size < 0.1:\n",
    "            label = \"negligible\"\n",
    "        elif effect_size < 0.3:\n",
    "            label = \"small\"\n",
    "        elif effect_size < 0.5:\n",
    "            label = \"medium\"\n",
    "        else:\n",
    "            label = \"large\"\n",
    "    \n",
    "    print(f\"Effect size interpretation: {label}\")\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(f\"SIGNIFICANT difference: p = {p_value:.4f} < {alpha}\")\n",
    "    else:\n",
    "        print(f\"No significant difference: p = {p_value:.4f} >= {alpha}\")\n",
    "    \n",
    "    # Store results in dictionary\n",
    "    stats_dict[q] = {\n",
    "        \"mean_B\": mean_B,\n",
    "        \"std_B\": std_B,\n",
    "        \"mean_C\": mean_C,\n",
    "        \"std_C\": std_C,\n",
    "        \"significant\": p_value < alpha\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of question keys to English question text\n",
    "QUESTION_DISPLAY = {\n",
    "    tes_const.QA_KEY: \"Useful to progress in the game?\",\n",
    "    tes_const.QB_KEY: \"Useful to learn Python programming?\",\n",
    "    tes_const.QC_KEY: \"Digital assistant in the future?\",\n",
    "    tes_const.QD_KEY: \"Help easy to understand?\",\n",
    "    tes_const.QE_KEY: \"Help was correct (without errors)?\"\n",
    "}\n",
    "\n",
    "# Use previously computed stats_dict\n",
    "summary_list = []\n",
    "for q in question_cols:\n",
    "    stats_q = stats_dict[q]  # fetch stored results\n",
    "    \n",
    "    summary_list.append({\n",
    "        'question': q,\n",
    "        'question_text': QUESTION_DISPLAY[q],\n",
    "        'mean_B': stats_q['mean_B'],\n",
    "        'std_B': stats_q['std_B'],\n",
    "        'mean_C': stats_q['mean_C'],\n",
    "        'std_C': stats_q['std_C'],\n",
    "        'significant': stats_q['significant']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_list)\n",
    "\n",
    "# Parameters for side-by-side bar chart\n",
    "x = np.arange(len(summary_df))\n",
    "width = 0.40\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot bars with error bars\n",
    "bars_B = ax.bar(x - width/2, summary_df['mean_B'], width, yerr=summary_df['std_B'], capsize=5, label='Group B', color='skyblue')\n",
    "bars_C = ax.bar(x + width/2, summary_df['mean_C'], width, yerr=summary_df['std_C'], capsize=5, label='Group C', color='salmon')\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(summary_df['question_text'], rotation=30, ha='right', fontsize=10)\n",
    "\n",
    "# Add axis labels and title\n",
    "ax.set_xlabel(\"Question\", fontsize=12)\n",
    "ax.set_ylabel(\"Mean score\", fontsize=12)\n",
    "# Add horizontal dashed line at 50%\n",
    "ax.axhline(y=50, color='red', linestyle='--', linewidth=1.5, label='50% reference')\n",
    "\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Annotate significance and values above bars\n",
    "for i, row in summary_df.iterrows():\n",
    "    # Position for significance star\n",
    "    y_star = max(row['mean_B'], row['mean_C']) + max(row['std_B'], row['std_C']) * 0.1\n",
    "    if row['significant']:\n",
    "        ax.text(i, y_star, '*', ha='center', va='bottom', fontsize=16, color='black')\n",
    "\n",
    "    # Add values above each bar (just above the bar, ignoring SD)\n",
    "    offset = 1.4  # small vertical margin above the bar\n",
    "    dx_b = 0.17   # horizontal shift (can adjust if needed)\n",
    "    dx_c = -0.17  # horizontal shift (can adjust if needed)\n",
    "    ax.text(i - width/2 - dx_b, row['mean_B'] + offset, f\"{row['mean_B']:.1f}\", ha='center', va='bottom', fontsize=10, color='black')\n",
    "    ax.text(i + width/2 - dx_c, row['mean_C'] + offset, f\"{row['mean_C']:.1f}\", ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust layout, save figure, and display\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/assistance_perception_BC.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 4/ Student perception of game resources and assistance [A]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "What is student perception of game resources and assistance in group A ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of questions to analyze: QI and QJ\n",
    "question_cols = tes_const.HELP_QUESTIONS\n",
    "\n",
    "# Mapping of question keys to English question text\n",
    "QUESTION_MAPPING = {\n",
    "    tes_const.QI_KEY: \"Did you find that the available resources in the game (instructions + programming memo) were sufficient to progress?\",\n",
    "    tes_const.QJ_KEY: \"Would you have liked to receive more help in the game?\"\n",
    "}\n",
    "df_A = post_test_data[post_test_data[tes_const.GROUP_ID_KEY] == tes_const.GROUP_A].copy()\n",
    "\n",
    "summary_list = []\n",
    "for q in question_cols:\n",
    "    values = df_A[q].dropna()\n",
    "    mean = values.mean()\n",
    "    std = values.std()\n",
    "    n = len(values)\n",
    "    summary_list.append({\n",
    "        'question_key': q,\n",
    "        'question_text': QUESTION_MAPPING[q],\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'n': n\n",
    "    })\n",
    "\n",
    "group_A_summary = pd.DataFrame(summary_list)\n",
    "\n",
    "# Display summary\n",
    "for _, row in group_A_summary.iterrows():\n",
    "    print(f\"\\n######## {row['question_key']} : {QUESTION_MAPPING[row['question_key']]} ########\")\n",
    "    print(f\"Group A (n={row['n']}): M = {row['mean']:.2f}, SD = {row['std']:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 5/ Feedback typology [C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 5.1/ Characteristics combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "What are the most common combinations of characteristics for the feedback in group C?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The feedback in group C contains within it a characterization expressed in XML format (`<feedback_caractéristiques>`).\n",
    "Here is an example of feedback:\n",
    "```xml\n",
    "<feedback>\n",
    "    <feedback_message>\n",
    "        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt.\n",
    "    <feedback_message>\n",
    "    <feedback_caractéristiques>\n",
    "        <combination>technical</combination>\n",
    "        <combination>error_pointed</combination>\n",
    "    </feedback_caractéristiques>\n",
    "</feedback>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only group C interactions\n",
    "interaction_C = interaction_data[interaction_data[int_const.GROUP_ID_DATA_KEY] == int_const.GROUP_C].copy()\n",
    "\n",
    "# Further filter: only feedback received from the assistant\n",
    "feedback_C = interaction_C[\n",
    "    (interaction_C[int_const.ACTION_DATA_KEY] == int_const.RECEIVED_ACTION) &\n",
    "    (interaction_C[int_const.OBJECT_DATA_KEY] == int_const.ASSISTANT_HELP_OBJECT)\n",
    "].copy()\n",
    "\n",
    "# Function to extract combinations from XML feedback\n",
    "def extract_combinations(feedback_xml):\n",
    "    if not feedback_xml or pd.isna(feedback_xml):\n",
    "        return []\n",
    "    try:\n",
    "        root = ET.fromstring(str(feedback_xml))\n",
    "        combis = [elem.text for elem in root.findall('.//feedback_caractéristiques/combination')]\n",
    "        return combis\n",
    "    except ET.ParseError:\n",
    "        return []\n",
    "\n",
    "# Apply the function: store a list of combinations per row\n",
    "feedback_C['combinations'] = feedback_C[int_const.CODE_DATA_KEY].apply(extract_combinations)\n",
    "\n",
    "# Count occurrences ignoring the order of elements\n",
    "all_combinations_tuples = [tuple(sorted(c)) for c in feedback_C['combinations']]\n",
    "combination_counts = Counter(all_combinations_tuples)\n",
    "\n",
    "# Convert to DataFrame and calculate percentage\n",
    "total = sum(combination_counts.values())\n",
    "combination_df = pd.DataFrame(\n",
    "    [(list(k), v, v / total * 100) for k, v in combination_counts.items()],\n",
    "    columns=['combination_list', 'count', 'percentage']\n",
    ").sort_values(by='count', ascending=False)\n",
    "\n",
    "print(combination_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 8\n",
    "top_df = combination_df.head(top_k).copy()\n",
    "top_labels = ['\\n'.join(c) for c in top_df['combination_list']]\n",
    "top_percentages = top_df['percentage'].values\n",
    "\n",
    "# Parameters for single-group bar chart\n",
    "x = np.arange(len(top_labels))\n",
    "width = 0.75\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot bars\n",
    "bars = ax.bar(x, top_percentages, width, label='Combinations')\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_labels, rotation=30, ha='right', fontsize=10)\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xlabel(\"Top characteristics combination\", fontsize=12)\n",
    "ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "ax.set_ylim(0, max(top_percentages)*1.08)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Layout adjustment, save figure, display\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/feedback_char_combination_C.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 5.2/ Characteristics type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "What are the most common characteristics for the feedback in group C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only group C interactions\n",
    "interaction_C = interaction_data[\n",
    "    interaction_data[int_const.GROUP_ID_DATA_KEY] == int_const.GROUP_C\n",
    "].copy()\n",
    "\n",
    "# Further filter: only feedback received from the assistant\n",
    "feedback_C = interaction_C[\n",
    "    (interaction_C[int_const.ACTION_DATA_KEY] == int_const.RECEIVED_ACTION) &\n",
    "    (interaction_C[int_const.OBJECT_DATA_KEY] == int_const.ASSISTANT_HELP_OBJECT)\n",
    "].copy()\n",
    "\n",
    "# Function to extract individual characteristics from XML feedback\n",
    "def extract_characteristics(feedback_xml):\n",
    "    if not feedback_xml or pd.isna(feedback_xml):\n",
    "        return []\n",
    "    try:\n",
    "        root = ET.fromstring(str(feedback_xml))\n",
    "        # Extract each individual characteristic\n",
    "        chars = [elem.text for elem in root.findall('.//feedback_caractéristiques/combination')]\n",
    "        return chars\n",
    "    except ET.ParseError:\n",
    "        return []\n",
    "\n",
    "# Extract list of characteristics (not combinations)\n",
    "feedback_C['characteristics'] = feedback_C[int_const.CODE_DATA_KEY].apply(extract_characteristics)\n",
    "\n",
    "# Flatten the list of lists\n",
    "flat_chars = [c for sublist in feedback_C['characteristics'] for c in sublist]\n",
    "\n",
    "# Count occurrences\n",
    "char_counts = Counter(flat_chars)\n",
    "\n",
    "# Convert to DataFrame + compute percentages\n",
    "total = sum(char_counts.values())\n",
    "\n",
    "char_df = pd.DataFrame(\n",
    "    [(k, v, v / total * 100) for k, v in char_counts.items()],\n",
    "    columns=['characteristic', 'count', 'percentage']\n",
    ").sort_values(by='count', ascending=False)\n",
    "\n",
    "print(char_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels and percentages\n",
    "labels = char_df['characteristic'].tolist()\n",
    "percentages = char_df['percentage'].tolist()\n",
    "\n",
    "# X positions\n",
    "x = np.arange(len(labels))\n",
    "width = 0.75  # bar width\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot bars\n",
    "bars = ax.bar(x, percentages, width, label='Characteristics')\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=30, ha='right', fontsize=10)\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xlabel(\"Feedback characteristics\", fontsize=12)\n",
    "ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "ax.set_ylim(0, max(percentages) * 1.1)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(\n",
    "        f'{height:.1f}%',\n",
    "        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "        xytext=(0, 3),\n",
    "        textcoords=\"offset points\",\n",
    "        ha='center', va='bottom', fontsize=10\n",
    "    )\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "# Layout + save + show\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/feedback_char_C.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
