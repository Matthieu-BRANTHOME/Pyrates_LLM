{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f2f5a2",
   "metadata": {},
   "source": [
    "![Logo Pyrates LLM](../assets/pyratesllm_logo_500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5be9f1",
   "metadata": {},
   "source": [
    "# **Notebook#02 : Analysis on axis 1**\n",
    "## [Impact of the digital assistant on the learner]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4583a",
   "metadata": {},
   "source": [
    "## 1/ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import students_constants as stu_const\n",
    "import interaction_constants as int_const\n",
    "import tests_constants  as tes_const\n",
    "\n",
    "# External\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39031f5",
   "metadata": {},
   "source": [
    "## 2/ Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data = pd.read_pickle(\"../data/interim/interaction_data.pkl\")\n",
    "pre_test_data = pd.read_pickle(\"../data/interim/pre_test_data.pkl\")\n",
    "post_test_data = pd.read_pickle(\"../data/interim/post_test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cd3d0",
   "metadata": {},
   "source": [
    "## 3/ Game progression (Q1.1) [A/B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1edae0",
   "metadata": {},
   "source": [
    "### 3.1/ Calculate game progression (index 0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d30c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all STARTED actions to find maximum level reached by each student\n",
    "started_actions = interaction_data[\n",
    "    interaction_data[int_const.ACTION_DATA_KEY] == int_const.STARTED_ACTION\n",
    "]\n",
    "\n",
    "# Find maximum level reached by each student\n",
    "max_level_per_student = started_actions.groupby(\n",
    "    int_const.GAME_ID_DATA_KEY\n",
    ")[int_const.LEVEL_DATA_KEY].max()\n",
    "\n",
    "print(f\"Number of games detected: {len(max_level_per_student)}\")\n",
    "\n",
    "student_progress_data = []\n",
    "\n",
    "for game_id in max_level_per_student.index:\n",
    "    max_level = max_level_per_student[game_id]\n",
    "    \n",
    "    # Get all traces for this student at his maximum level\n",
    "    student_level_data = interaction_data[\n",
    "        (interaction_data[int_const.GAME_ID_DATA_KEY] == game_id) & \n",
    "        (interaction_data[int_const.LEVEL_DATA_KEY] == max_level)\n",
    "    ]\n",
    "    \n",
    "    # Maximum progression\n",
    "    max_progression = student_level_data[int_const.GAME_PROGRESSION_DATA_KEY].max()\n",
    "    \n",
    "    # Group id\n",
    "    group = student_level_data[int_const.GROUP_ID_DATA_KEY].iloc[0]\n",
    "\n",
    "    # Results aggregation \n",
    "    student_progress_data.append({\n",
    "        'game_id': game_id,\n",
    "        'group_id': group,\n",
    "        'max_level': max_level,\n",
    "        'max_progression': max_progression\n",
    "    })\n",
    "\n",
    "# Create progress dataframe\n",
    "progress_df = pd.DataFrame(student_progress_data)\n",
    "\n",
    "# Calculate progress index (0-100 points)\n",
    "# - Each completed level gives 12.5 points (100/8)\n",
    "# - For current level, progression percentage gives fraction of 12.5 points\n",
    "def calculate_progress_index(max_level, max_progression):\n",
    "    completed_levels_points = (max_level - 1) * (100 / 8)\n",
    "    current_level_points = (max_progression / 100) * (100 / 8)\n",
    "    return min(completed_levels_points + current_level_points, 100)\n",
    "\n",
    "progress_df['progress_index'] = progress_df.apply(\n",
    "    lambda row: calculate_progress_index(row['max_level'], row['max_progression']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Number of progress entries computed: {len(progress_df)}\")\n",
    "# Export to Excel for debug\n",
    "progress_df.to_excel(\"../debug/debug_students_game_progression.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa61b3e",
   "metadata": {},
   "source": [
    "### 3.2/ Test A VS (B+C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e6ac1",
   "metadata": {},
   "source": [
    "Is there a difference in game progression between students from groups A and students from group B+C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ab77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract progress data for each group\n",
    "group_a_progress = progress_df[progress_df['group_id'] == 'A']['progress_index']\n",
    "group_b_progress = progress_df[progress_df['group_id'] == 'B']['progress_index']\n",
    "group_c_progress = progress_df[progress_df['group_id'] == 'C']['progress_index']\n",
    "# Combine B and C into one group\n",
    "group_bc_progress = pd.concat([group_b_progress, group_c_progress])\n",
    "\n",
    "# Descriptive statistics\n",
    "average_progress_A = group_a_progress.mean()\n",
    "average_progress_BC = group_bc_progress.mean()\n",
    "\n",
    "std_progress_A = group_a_progress.std()\n",
    "std_progress_BC = group_bc_progress.std()\n",
    "\n",
    "mean_diff = average_progress_BC - average_progress_A\n",
    "percent_increase = (mean_diff / average_progress_A) * 100\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A: n = {len(group_a_progress)}, mean = {average_progress_A:.2f}, std = {std_progress_A:.2f}\")\n",
    "print(f\"Group B+C: n = {len(group_bc_progress)}, mean = {average_progress_BC:.2f}, std = {std_progress_BC:.2f}\")\n",
    "print(f\".   Difference in mean (B+C - A): {mean_diff:.2f}\")\n",
    "print(f\".   Percentage increase from Group A: {percent_increase:.2f}%\")\n",
    "\n",
    "alpha=0.05\n",
    "print(f\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_A = stats.shapiro(group_a_progress)\n",
    "shapiro_BC = stats.shapiro(group_bc_progress)\n",
    "print(f\"Shapiro A: p-value = {shapiro_A.pvalue:.4f}\")\n",
    "print(f\"Shapiro B+C: p-value = {shapiro_BC.pvalue:.4f}\")\n",
    "\n",
    "# Normality conclusions\n",
    "if shapiro_A.pvalue >= alpha:\n",
    "    print(\"Group A: data appears normally distributed\")\n",
    "else:\n",
    "    print(\"Group A: data does not appear normally distributed\")\n",
    "\n",
    "if shapiro_BC.pvalue >= alpha:\n",
    "    print(\"Group B+C: data appears normally distributed\")\n",
    "else:\n",
    "    print(\"Group B+C: data does not appear normally distributed\")\n",
    "\n",
    "print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_p = stats.levene(group_a_progress, group_bc_progress).pvalue\n",
    "print(f\"Levene A vs B/C p-value = {levene_p:.4f}\")\n",
    "\n",
    "# Variance conclusion\n",
    "if levene_p >= alpha:\n",
    "    print(\"Variances are similar between groups\")\n",
    "else:\n",
    "    print(\"Variances differ between groups\")\n",
    "\n",
    "print(f\"\\n=== TEST RESULTS ===\")\n",
    "# Decide which test to use\n",
    "normal_A = shapiro_A.pvalue >= alpha\n",
    "normal_BC = shapiro_BC.pvalue >= alpha\n",
    "levene_AB_C = levene_p >= 0.05\n",
    "\n",
    "if normal_A and normal_BC and levene_AB_C:\n",
    "    print(\"Using independent t-test (parametric)\")\n",
    "    t_stat, p_value = stats.ttest_ind(group_a_progress, group_bc_progress, equal_var=True)\n",
    "else:\n",
    "    print(\"Using Mann-Whitney U test (non-parametric)\")\n",
    "    t_stat, p_value = stats.mannwhitneyu(group_a_progress, group_bc_progress, alternative='two-sided')\n",
    "\n",
    "print(f\"Test statistic = {t_stat:.4f}\")\n",
    "print(f\"P-value = {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"SIGNIFICANT: p-value = {p_value:.4f} < alpha = {alpha}\")\n",
    "    print(\"There are statistically significant differences between Group A and Group B+C\")\n",
    "else:\n",
    "    print(f\"NOT SIGNIFICANT: p-value = {p_value:.4f} > alpha = {alpha}\")\n",
    "    print(\"No statistically significant differences between Group A and Group B+C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a4ac73",
   "metadata": {},
   "source": [
    "### 3.3/ Test A VS B VS C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4701935",
   "metadata": {},
   "source": [
    "Is there a difference in game progression between students from groups A, B, and C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65229b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "average_progress_A = group_a_progress.mean()\n",
    "average_progress_B = group_b_progress.mean()\n",
    "average_progress_C = group_c_progress.mean()\n",
    "\n",
    "diff_B = average_progress_B - average_progress_A\n",
    "percent_increase_B = (diff_B / average_progress_A) * 100\n",
    "\n",
    "diff_C = average_progress_C - average_progress_A\n",
    "percent_increase_C = (diff_C / average_progress_A) * 100\n",
    "\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A: n = {len(group_a_progress)}, mean = {average_progress_A:.2f}, std = {group_a_progress.std():.2f}\")\n",
    "print(f\"Group B: n = {len(group_b_progress)}, mean = {average_progress_B:.2f}, std = {group_b_progress.std():.2f}\")\n",
    "print(f\".   diff vs A = {diff_B:.2f}, increase = {percent_increase_B:.2f}%\")\n",
    "print(f\"Group C: n = {len(group_c_progress)}, mean = {average_progress_C:.2f}, std = {group_c_progress.std():.2f}\")\n",
    "print(f\".   diff vs A = {diff_C:.2f}, increase = {percent_increase_C:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "print(f\"=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_A = stats.shapiro(group_a_progress)\n",
    "shapiro_B = stats.shapiro(group_b_progress)\n",
    "shapiro_C = stats.shapiro(group_c_progress)\n",
    "\n",
    "print(f\"Group A: p-value = {shapiro_A.pvalue:.4f}\")\n",
    "print(f\"Group B: p-value = {shapiro_B.pvalue:.4f}\")\n",
    "print(f\"Group C: p-value = {shapiro_C.pvalue:.4f}\")\n",
    "\n",
    "# Check if all groups are normally distributed\n",
    "all_normal = all(p >= alpha for p in [shapiro_A.pvalue, shapiro_B.pvalue, shapiro_C.pvalue])\n",
    "\n",
    "if all_normal:\n",
    "    print(\"All groups follow normal distribution -> ANOVA is applicable.\")\n",
    "else:\n",
    "    print(\"At least one group is not normally distributed -> Prefer Kruskal-Wallis test.\")\n",
    "\n",
    "print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_test = stats.levene(group_a_progress, group_b_progress, group_c_progress)\n",
    "print(f\"Levene's test for homogeneity of variances: p-value = {levene_test.pvalue:.4f}\")\n",
    "\n",
    "if levene_test.pvalue >= alpha:\n",
    "    print(\"Variances are homogeneous\")\n",
    "else:\n",
    "    print(\"Variances are not homogeneous\")\n",
    "\n",
    "\n",
    "# Prepare data for overall tests\n",
    "all_progress = pd.concat([\n",
    "    pd.DataFrame({'group': 'A', 'progress': group_a_progress}),\n",
    "    pd.DataFrame({'group': 'B', 'progress': group_b_progress}),\n",
    "    pd.DataFrame({'group': 'C', 'progress': group_c_progress})\n",
    "])\n",
    "\n",
    "# ANOVA (parametric)\n",
    "anova_result = stats.f_oneway(group_a_progress, group_b_progress, group_c_progress)\n",
    "# One-way : one factor (group)\n",
    "print(f\"\\n=== ONE-WAY ANOVA RESULTS ===\")\n",
    "print(f\"F-statistic: {anova_result.statistic:.4f}\")\n",
    "print(f\"P-value: {anova_result.pvalue:.4f}\")\n",
    "\n",
    "# Kruskal-Wallis test (non-parametric)\n",
    "kruskal_result = stats.kruskal(group_a_progress, group_b_progress, group_c_progress)\n",
    "print(f\"\\n=== KRUSKAL-WALLIS TEST RESULTS ===\")\n",
    "print(f\"H-statistic: {kruskal_result.statistic:.4f}\")\n",
    "print(f\"P-value: {kruskal_result.pvalue:.4f}\")\n",
    "\n",
    "# Interpretation of overall test\n",
    "if all_normal and levene_test.pvalue >= alpha:\n",
    "    overall_pvalue = anova_result.pvalue\n",
    "    test_used = \"ANOVA\"\n",
    "else:\n",
    "    overall_pvalue = kruskal_result.pvalue\n",
    "    test_used = \"Kruskal-Wallis\"\n",
    "\n",
    "print(f\"\\n=== OVERALL INTERPRETATION (using {test_used}) ===\")\n",
    "if overall_pvalue < alpha:\n",
    "    print(f\"SIGNIFICANT: p-value = {overall_pvalue:.4f} < alpha = {alpha}\")\n",
    "    print(\"There are statistically significant differences between at least two groups\")\n",
    "else:\n",
    "    print(f\"NOT SIGNIFICANT: p-value = {overall_pvalue:.4f} > alpha = {alpha}\")\n",
    "    print(\"No statistically significant differences between groups\")\n",
    "\n",
    "# POST-HOC TESTS (if significant overall difference)\n",
    "if overall_pvalue < alpha:\n",
    "    print(f\"\\n=== POST-HOC PAIRWISE COMPARISONS ===\")\n",
    "    \n",
    "    # For parametric data: Tukey HSD\n",
    "    if test_used == \"ANOVA\":\n",
    "        print(\"Tukey HSD Post-hoc Test:\")\n",
    "        tukey = pairwise_tukeyhsd(endog=all_progress['progress'], groups=all_progress['group'], alpha=alpha)\n",
    "        print(tukey)\n",
    "        \n",
    "        # Extract significant pairs\n",
    "        print(\"\\nSignificant pairwise differences:\")\n",
    "        for i in range(len(tukey._results[0])):\n",
    "            if tukey._results[4][i]:  # If reject (True)\n",
    "                group1, group2 = tukey._results[1][i], tukey._results[2][i]\n",
    "                meandiff = tukey._results[3][i]\n",
    "                pval = tukey._results[4][i]\n",
    "                print(f\"  {group1} vs {group2}: SIGNIFICANT (mean diff = {meandiff:.2f}, p = {pval:.4f})\")\n",
    "    \n",
    "    # For non-parametric data: Mann-Whitney U tests with Bonferroni correction\n",
    "    else:\n",
    "        print(\"Mann-Whitney U tests with Bonferroni correction:\")\n",
    "        pairs = [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
    "        bonferroni_alpha = alpha / len(pairs)  # Bonferroni correction\n",
    "        \n",
    "        for pair in pairs:\n",
    "            group1, group2 = pair\n",
    "            data1 = group_a_progress if group1 == 'A' else (group_b_progress if group1 == 'B' else group_c_progress)\n",
    "            data2 = group_a_progress if group2 == 'A' else (group_b_progress if group2 == 'B' else group_c_progress)\n",
    "            \n",
    "            u_stat, p_value = stats.mannwhitneyu(data1, data2)\n",
    "            adjusted_p = p_value * len(pairs)  # Bonferroni adjustment\n",
    "            significance = \"SIGNIFICANT\" if adjusted_p < alpha else \"not significant\"\n",
    "            \n",
    "            print(f\"  {group1} vs {group2}: p = {p_value:.4f}, \"\n",
    "                  f\"adjusted p = {adjusted_p:.4f} -> {significance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b123a3f",
   "metadata": {},
   "source": [
    "## 4/ Learning gain (Q1.2) [A/B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df2032",
   "metadata": {},
   "source": [
    "### 4.1/ Learning gain calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b408dc",
   "metadata": {},
   "source": [
    "The learning gain calculation is based on ANSWERS_SCORES dictionary (see `scr/tests_constants.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate maximum score\n",
    "max_score_general = sum(max(answer.values()) for answer in tes_const.ANSWERS_SCORES.values())\n",
    "\n",
    "# Score calculation function\n",
    "def calculate_score(student, max_score):\n",
    "    score = 0\n",
    "    for question, answer in student.items():\n",
    "        if question in tes_const.ANSWERS_SCORES and answer in tes_const.ANSWERS_SCORES[question]:\n",
    "            score += tes_const.ANSWERS_SCORES[question][answer]\n",
    "    return round((score/max_score)*100)\n",
    "\n",
    "groups = [tes_const.GROUP_A, tes_const.GROUP_B, tes_const.GROUP_C]\n",
    "scores_data = {}\n",
    "\n",
    "for group in groups:\n",
    "    # Filter and calculate scores\n",
    "    pre_temp = pre_test_data[pre_test_data[tes_const.GROUP_ID_KEY] == group].copy()\n",
    "    post_temp = post_test_data[post_test_data[tes_const.GROUP_ID_KEY] == group].copy()\n",
    "    \n",
    "    pre_temp['pre_score'] = pre_temp.apply(calculate_score, axis=1, max_score=max_score_general)\n",
    "    post_temp['post_score'] = post_temp.apply(calculate_score, axis=1, max_score=max_score_general)\n",
    "    \n",
    "    # Merge and calculate gain\n",
    "    scores_df = pd.merge(\n",
    "        pre_temp[[tes_const.STUDENT_ID_KEY, 'pre_score']],\n",
    "        post_temp[[tes_const.STUDENT_ID_KEY, 'post_score']],\n",
    "        on=tes_const.STUDENT_ID_KEY,\n",
    "        how='inner' # the student must have a pre-test score AND a post-test score\n",
    "    )\n",
    "    scores_df['learning_gain'] = scores_df['post_score'] - scores_df['pre_score']\n",
    "    \n",
    "    scores_data[group] = scores_df\n",
    "    print(f\"Group {group}: {len(scores_df)}/{sum(1 for s in stu_const.ALL_STUDENTS if s[stu_const.GROUP_ID] == group)} students with both pre and post tests\")\n",
    "    \n",
    "    # Export\n",
    "    scores_df.to_excel(f\"../debug/debug_learning_gain_{group}.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce11ff",
   "metadata": {},
   "source": [
    "### 4.2/ Intra-group learning gain analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37f589",
   "metadata": {},
   "source": [
    "Do students demonstrate learning gains using Pyrates in their respective groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc330656",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "groups = [tes_const.GROUP_A, tes_const.GROUP_B, tes_const.GROUP_C]\n",
    "for group in groups:\n",
    "    scores_df = scores_data[group]\n",
    "    pre_scores = scores_df['pre_score']\n",
    "    post_scores = scores_df['post_score']\n",
    "    learning_gains = scores_df['learning_gain']\n",
    "    print(f\"\\n=======================================\")\n",
    "    print(f\"GROUP {group} INTRA-GROUP ANALYSIS\")\n",
    "    print(f\"========================================\")\n",
    "\n",
    "    print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "\n",
    "    print(f\"Pre-test: M = {pre_scores.mean():.2f}, SD = {pre_scores.std():.2f}\")\n",
    "    print(f\"Post-test: M = {post_scores.mean():.2f}, SD = {post_scores.std():.2f}\")\n",
    "    print(f\"Learning gain: M = {learning_gains.mean():.2f}, SD = {learning_gains.std():.2f}\")\n",
    "    \n",
    "    print(f\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "    # Shapiro-Wilk test for pre-post differences\n",
    "    shapiro_gain = stats.shapiro(learning_gains)\n",
    "    print(f\"Shapiro-Wilk test for learning gains: p-value = {shapiro_gain.pvalue:.4f}\")\n",
    "    \n",
    "    # Check normality\n",
    "    if shapiro_gain.pvalue >= 0.05:\n",
    "        print(\"Learning gains are normally distributed -> Paired T-test is applicable.\")\n",
    "        normal_distribution = True\n",
    "    else:\n",
    "        print(\"Learning gains are not normally distributed -> Prefer Wilcoxon test.\")\n",
    "        normal_distribution = False\n",
    "    \n",
    "    print(f\"\\n=== TEST RESULTS ===\")\n",
    "    # Paired T-test\n",
    "    t_test = stats.ttest_rel(pre_scores, post_scores)\n",
    "    print(f\"Paired T-test: t = {t_test.statistic:.4f}, p-value = {t_test.pvalue:.4f}\")\n",
    "    \n",
    "    # Wilcoxon signed-rank test\n",
    "    wilcoxon_test = stats.wilcoxon(pre_scores, post_scores)\n",
    "    print(f\"Wilcoxon test: W = {wilcoxon_test.statistic:.4f}, p-value = {wilcoxon_test.pvalue:.4f}\")\n",
    "    \n",
    "    # Choose appropriate test based on normality\n",
    "    if normal_distribution:\n",
    "        recommended_pvalue = t_test.pvalue\n",
    "        test_used = \"Paired T-test\"\n",
    "    else:\n",
    "        recommended_pvalue = wilcoxon_test.pvalue\n",
    "        test_used = \"Wilcoxon test\"\n",
    "    \n",
    "    # Interpretation\n",
    "    print(f\"Results (using {test_used}) :\")\n",
    "    \n",
    "    if recommended_pvalue < alpha:\n",
    "        print(f\"SIGNIFICANT: p-value = {recommended_pvalue:.4f} < alpha = {alpha}\")\n",
    "        if learning_gains.mean() > 0:\n",
    "            print(f\"   Significant learning gain observed (+{learning_gains.mean():.2f} points)\")\n",
    "        else:\n",
    "            print(f\"   Significant learning loss observed ({learning_gains.mean():.2f} points)\")\n",
    "    else:\n",
    "        print(f\"NOT SIGNIFICANT: p-value = {recommended_pvalue:.4f} > alpha = {alpha}\")\n",
    "        print(\"   No significant learning gain observed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c39938",
   "metadata": {},
   "source": [
    "### 4.3/ Inter-group learning gain comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e06770",
   "metadata": {},
   "source": [
    "#### 4.3.1/ Test A VS (B+C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efcdd2",
   "metadata": {},
   "source": [
    "Is there a difference in learning gains between students from groups A and those from group B+C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1609dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract learning gains\n",
    "learning_gains_A = scores_data['A']['learning_gain']\n",
    "learning_gains_BC = pd.concat([scores_data['B']['learning_gain'], scores_data['C']['learning_gain']])\n",
    "\n",
    "# Descriptive statistics\n",
    "mean_A = learning_gains_A.mean()\n",
    "mean_BC = learning_gains_BC.mean()\n",
    "std_A = learning_gains_A.std()\n",
    "std_BC = learning_gains_BC.std()\n",
    "diff_A_BC = mean_A - mean_BC\n",
    "percent_reduction_BC = (diff_A_BC / mean_A) * 100\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A (n={len(learning_gains_A)}): M = {mean_A:.2f}, SD = {std_A:.2f}\")\n",
    "print(f\"Group B+C (n={len(learning_gains_BC)}): M = {mean_BC:.2f}, SD = {std_BC:.2f}\")\n",
    "print(f\".   Difference (A - B+C) = {diff_A_BC:.2f}\")\n",
    "print(f\".   Percentage reduction compared to A = {percent_reduction_BC:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "# Normality test\n",
    "print(\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_A = stats.shapiro(learning_gains_A)\n",
    "shapiro_BC = stats.shapiro(learning_gains_BC)\n",
    "print(f\"Group A: p-value = {shapiro_A.pvalue:.4f} ->{'normally distributed' if shapiro_A.pvalue >= alpha else 'not normally distributed'}\")\n",
    "print(f\"Group B+C: p-value = {shapiro_BC.pvalue:.4f} -> {'normally distributed' if shapiro_BC.pvalue >= alpha else 'not normally distributed'}\")\n",
    "\n",
    "# Levene test for equal variances\n",
    "print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_p = stats.levene(learning_gains_A, learning_gains_BC).pvalue\n",
    "print(f\"Levene p-value = {levene_p:.4f} -> {'variances are similar' if levene_p >= alpha else 'variances differ'}\")\n",
    "\n",
    "\n",
    "print(f\"\\n=== TEST RESULTS ===\")\n",
    "# Choose statistical test\n",
    "normal_A = shapiro_A.pvalue >= alpha\n",
    "normal_BC = shapiro_BC.pvalue >= alpha\n",
    "equal_var = levene_p >= alpha\n",
    "\n",
    "if normal_A and normal_BC and equal_var:\n",
    "    print(\"Using independent t-test (parametric)\")\n",
    "    stat, p_value = stats.ttest_ind(learning_gains_A, learning_gains_BC, equal_var=True)\n",
    "else:\n",
    "    print(\"Using Mann-Whitney U test (non-parametric)\")\n",
    "    stat, p_value = stats.mannwhitneyu(learning_gains_A, learning_gains_BC, alternative='two-sided')\n",
    "\n",
    "print(f\"Test statistic = {stat:.4f}\")\n",
    "print(f\"P-value = {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"SIGNIFICANT difference: p = {p_value:.4f} < {alpha}\")\n",
    "else:\n",
    "    print(f\"No significant difference: p = {p_value:.4f} >= {alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962686c9",
   "metadata": {},
   "source": [
    "#### 4.3.2/ Test A VS B VS C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567a379",
   "metadata": {},
   "source": [
    "Is there a difference in learning gains between students from groups A, B, and C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract learning gains for each group\n",
    "learning_gains_A = scores_data['A']['learning_gain']\n",
    "learning_gains_B = scores_data['B']['learning_gain'] \n",
    "learning_gains_C = scores_data['C']['learning_gain']\n",
    "\n",
    "# Descriptive statistics\n",
    "average_gain_A = learning_gains_A.mean()\n",
    "average_gain_B = learning_gains_B.mean()\n",
    "average_gain_C = learning_gains_C.mean()\n",
    "diff_B_vs_A = average_gain_A - average_gain_B\n",
    "diff_C_vs_A = average_gain_A - average_gain_C\n",
    "\n",
    "percent_reduction_B = (diff_B_vs_A / average_gain_A) * 100\n",
    "percent_reduction_C = (diff_C_vs_A / average_gain_A) * 100\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A (n={len(learning_gains_A)}): M = {average_gain_A:.2f}, SD = {learning_gains_A.std():.2f}\")\n",
    "print(f\"Group B (n={len(learning_gains_B)}): M = {average_gain_B:.2f}, SD = {learning_gains_B.std():.2f}\")\n",
    "print(f\".   B vs A: Mean difference = {diff_B_vs_A:.2f}, Percentage reduction = {percent_reduction_B:.2f}%\")\n",
    "print(f\"Group C (n={len(learning_gains_C)}): M = {average_gain_C:.2f}, SD = {learning_gains_C.std():.2f}\")\n",
    "print(f\".   C vs A: Mean difference = {diff_C_vs_A:.2f}, Percentage reduction = {percent_reduction_C:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "# Shapiro-Wilk normality test\n",
    "print(f\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_A = stats.shapiro(learning_gains_A)\n",
    "shapiro_B = stats.shapiro(learning_gains_B)\n",
    "shapiro_C = stats.shapiro(learning_gains_C)\n",
    "\n",
    "print(f\"Group A: p-value = {shapiro_A.pvalue:.4f}\")\n",
    "print(f\"Group B: p-value = {shapiro_B.pvalue:.4f}\")\n",
    "print(f\"Group C: p-value = {shapiro_C.pvalue:.4f}\")\n",
    "\n",
    "# Check if all groups are normally distributed\n",
    "all_normal = all(p >= alpha for p in [shapiro_A.pvalue, shapiro_B.pvalue, shapiro_C.pvalue])\n",
    "\n",
    "if all_normal:\n",
    "    print(\"All groups follow normal distribution -> ANOVA is applicable.\")\n",
    "else:\n",
    "    print(\"At least one group is not normally distributed -> Prefer Kruskal-Wallis test.\")\n",
    "\n",
    "print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_test = stats.levene(learning_gains_A, learning_gains_B, learning_gains_C)\n",
    "print(f\"Levene's test for homogeneity of variances: p-value = {levene_test.pvalue:.4f}\")\n",
    "\n",
    "if levene_test.pvalue >= alpha:\n",
    "    print(\"Variances are homogeneous\")\n",
    "else:\n",
    "    print(\"Variances are not homogeneous\")\n",
    "\n",
    "# Prepare data for overall tests\n",
    "all_gains = pd.concat([\n",
    "    pd.DataFrame({'group': 'A', 'gain': learning_gains_A}),\n",
    "    pd.DataFrame({'group': 'B', 'gain': learning_gains_B}),\n",
    "    pd.DataFrame({'group': 'C', 'gain': learning_gains_C})\n",
    "])\n",
    "\n",
    "# ANOVA (parametric)\n",
    "anova_result = stats.f_oneway(learning_gains_A, learning_gains_B, learning_gains_C)\n",
    "print(f\"\\n=== ONE-WAY ANOVA RESULTS ===\")\n",
    "print(f\"F-statistic: {anova_result.statistic:.4f}\")\n",
    "print(f\"P-value: {anova_result.pvalue:.4f}\")\n",
    "\n",
    "# Kruskal-Wallis test (non-parametric)\n",
    "kruskal_result = stats.kruskal(learning_gains_A, learning_gains_B, learning_gains_C)\n",
    "print(f\"\\n=== KRUSKAL-WALLIS TEST RESULTS ===\")\n",
    "print(f\"H-statistic: {kruskal_result.statistic:.4f}\")\n",
    "print(f\"P-value: {kruskal_result.pvalue:.4f}\")\n",
    "\n",
    "# Interpretation of overall test\n",
    "if all_normal and levene_test.pvalue >= 0.05:\n",
    "    overall_pvalue = anova_result.pvalue\n",
    "    test_used = \"ANOVA\"\n",
    "else:\n",
    "    overall_pvalue = kruskal_result.pvalue\n",
    "    test_used = \"Kruskal-Wallis\"\n",
    "\n",
    "print(f\"\\n=== OVERALL INTERPRETATION (using {test_used}) ===\")\n",
    "if overall_pvalue < alpha:\n",
    "    print(f\"SIGNIFICANT: p-value = {overall_pvalue:.4f} < alpha = {alpha}\")\n",
    "    print(\"   There are statistically significant differences in learning gains between at least two groups\")\n",
    "else:\n",
    "    print(f\"NOT SIGNIFICANT: p-value = {overall_pvalue:.4f} > alpha = {alpha}\")\n",
    "    print(\"   No statistically significant differences in learning gains between groups\")\n",
    "\n",
    "# POST-HOC TESTS (if significant overall difference)\n",
    "if overall_pvalue < alpha:\n",
    "    print(f\"\\n=== POST-HOC PAIRWISE COMPARISONS ===\")\n",
    "    \n",
    "    # For parametric data: Tukey HSD\n",
    "    if test_used == \"ANOVA\":\n",
    "        print(\"Tukey HSD Post-hoc Test:\")\n",
    "        tukey = pairwise_tukeyhsd(endog=all_gains['gain'], groups=all_gains['group'], alpha=alpha)\n",
    "        print(tukey)\n",
    "        \n",
    "        # Extract significant pairs\n",
    "        print(\"\\nSignificant pairwise differences:\")\n",
    "        for i in range(len(tukey._results[0])):\n",
    "            if tukey._results[4][i]:  # If reject (True)\n",
    "                group1, group2 = tukey._results[1][i], tukey._results[2][i]\n",
    "                meandiff = tukey._results[3][i]\n",
    "                pval = tukey._results[4][i]\n",
    "                print(f\"  {group1} vs {group2}: SIGNIFICANT (mean diff = {meandiff:.2f}, p = {pval:.4f})\")\n",
    "    \n",
    "    # For non-parametric data: Mann-Whitney U tests with Bonferroni correction\n",
    "    else:\n",
    "        print(\"Mann-Whitney U tests with Bonferroni correction:\")\n",
    "        pairs = [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
    "        bonferroni_alpha = alpha / len(pairs)\n",
    "        \n",
    "        for pair in pairs:\n",
    "            group1, group2 = pair\n",
    "            data1 = learning_gains_A if group1 == 'A' else (learning_gains_B if group1 == 'B' else learning_gains_C)\n",
    "            data2 = learning_gains_A if group2 == 'A' else (learning_gains_B if group2 == 'B' else learning_gains_C)\n",
    "            \n",
    "            u_stat, p_value = stats.mannwhitneyu(data1, data2)\n",
    "            adjusted_p = p_value * len(pairs)\n",
    "            significance = \"SIGNIFICANT\" if adjusted_p < alpha else \"not significant\"\n",
    "            \n",
    "            print(f\"  {group1} vs {group2}: p = {p_value:.4f}, adjusted p = {adjusted_p:.4f} -> {significance}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7495c2",
   "metadata": {},
   "source": [
    "## 5/ Teacher solicitation (Q1.3) [A/B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db934c6",
   "metadata": {},
   "source": [
    "### 5.1/ Teacher solicitation calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all groups in one go\n",
    "groups = [int_const.GROUP_A, int_const.GROUP_B, int_const.GROUP_C]\n",
    "calls_data = {}\n",
    "\n",
    "for group in groups:\n",
    "    # Filter and count teacher calls\n",
    "    group_data = interaction_data[interaction_data[int_const.GROUP_ID_DATA_KEY] == group]\n",
    "    \n",
    "    teacher_calls = group_data[\n",
    "        (group_data[int_const.ACTION_DATA_KEY] == int_const.RECEIVED_ACTION) &\n",
    "        (group_data[int_const.OBJECT_DATA_KEY] == int_const.TEACHER_HELP_OBJECT)\n",
    "    ]\n",
    "    \n",
    "    # Count per student\n",
    "    calls_per_student = teacher_calls.groupby(int_const.GAME_ID_DATA_KEY).size()\n",
    "    \n",
    "    # Get valid students and fill missing with 0\n",
    "    valid_students = [s[stu_const.GAME_ID] for s in stu_const.ALL_STUDENTS if s[stu_const.GROUP_ID] == group]\n",
    "    calls_per_student = calls_per_student.reindex(valid_students, fill_value=0)\n",
    "    \n",
    "    calls_data[group] = calls_per_student\n",
    "    print(f\"Group {group}: {len(calls_per_student)} students processed\")\n",
    "    \n",
    "    # Export\n",
    "    calls_per_student.to_excel(f\"../debug/debug_teacher_solicitation_per_student_{group}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d9a7a",
   "metadata": {},
   "source": [
    "### 5.2/ Test A VS (B+C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81fed0f",
   "metadata": {},
   "source": [
    "Is there a difference in teacher solicitation between students from groups A and students from group B+C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract calls data for each group\n",
    "calls_A = calls_data['A']\n",
    "calls_B = calls_data['B']\n",
    "calls_C = calls_data['C']\n",
    "\n",
    "# Combine B and C groups\n",
    "calls_BC = pd.concat([calls_B, calls_C])\n",
    "\n",
    "# Descriptive statistics\n",
    "mean_A = calls_A.mean()\n",
    "mean_BC = calls_BC.mean()\n",
    "std_A = calls_A.std()\n",
    "std_BC = calls_BC.std()\n",
    "diff_A_BC = mean_A - mean_BC\n",
    "percent_reduction_BC = (diff_A_BC / mean_A) * 100\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A (n={len(calls_A)}): M = {mean_A:.2f}, SD = {std_A:.2f}\")\n",
    "print(f\"Group B+C (n={len(calls_BC)}): M = {mean_BC:.2f}, SD = {std_BC:.2f}\")\n",
    "print(f\".   Difference (A - B+C) = {diff_A_BC:.2f}\")\n",
    "print(f\".   Percentage reduction compared to A = {percent_reduction_BC:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "# Shapiro-Wilk normality test\n",
    "print(\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_A = stats.shapiro(calls_A)\n",
    "shapiro_BC = stats.shapiro(calls_BC)\n",
    "print(f\"Group A: p-value = {shapiro_A.pvalue:.4f} -> {'normally distributed' if shapiro_A.pvalue >= alpha else 'not normally distributed'}\")\n",
    "print(f\"Group B+C: p-value = {shapiro_BC.pvalue:.4f} -> {'normally distributed' if shapiro_BC.pvalue >= alpha else 'not normally distributed'}\")\n",
    "\n",
    "# Levene test for equal variances\n",
    "print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_p = stats.levene(calls_A, calls_BC).pvalue\n",
    "print(f\"Levene p-value = {levene_p:.4f} -> {'variances are similar' if levene_p >= alpha else 'variances differ'}\")\n",
    "\n",
    "print(f\"\\n=== TEST RESULTS ===\")\n",
    "# Choose statistical test\n",
    "normal_A = shapiro_A.pvalue >= alpha\n",
    "normal_BC = shapiro_BC.pvalue >= alpha\n",
    "equal_var = levene_p >= alpha\n",
    "\n",
    "if normal_A and normal_BC and equal_var:\n",
    "    print(\"Using independent t-test (parametric)\")\n",
    "    stat, p_value = stats.ttest_ind(calls_A, calls_BC, equal_var=True)\n",
    "else:\n",
    "    print(\"Using Mann-Whitney U test (non-parametric)\")\n",
    "    stat, p_value = stats.mannwhitneyu(calls_A, calls_BC, alternative='two-sided')\n",
    "\n",
    "print(f\"Test statistic = {stat:.4f}\")\n",
    "print(f\"P-value = {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"SIGNIFICANT difference: p = {p_value:.4f} < {alpha}\")\n",
    "    print(\"There are statistically significant differences in teacher solicitation between Group A and Group B+C\")\n",
    "else:\n",
    "    print(f\"No significant difference: p = {p_value:.4f} >= {alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a622cd",
   "metadata": {},
   "source": [
    "### 5.3/ Test A VS B VS C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef6d84",
   "metadata": {},
   "source": [
    "Is there a difference in teacher solicitation between students from groups A, B, and C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc509b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "average_calls_A = calls_A.mean()\n",
    "average_calls_B = calls_B.mean()\n",
    "average_calls_C = calls_C.mean()\n",
    "\n",
    "diff_B_A = average_calls_A - average_calls_B\n",
    "diff_C_A = average_calls_A - average_calls_C\n",
    "\n",
    "percent_reduction_B = (diff_B_A / average_calls_A) * 100\n",
    "percent_reduction_C = (diff_C_A / average_calls_A) * 100\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A (n={len(calls_A)}): M = {average_calls_A:.2f}, SD = {calls_A.std():.2f}\")\n",
    "print(f\"Group B (n={len(calls_B)}): M = {average_calls_B:.2f}, SD = {calls_B.std():.2f}\")\n",
    "print(f\".   B vs A: Difference = {diff_B_A:.2f}, Percentage reduction = {percent_reduction_B:.2f}%\")\n",
    "print(f\"Group C (n={len(calls_C)}): M = {average_calls_C:.2f}, SD = {calls_C.std():.2f}\")\n",
    "print(f\".   C vs A: Difference = {diff_C_A:.2f}, Percentage reduction = {percent_reduction_C:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "# Shapiro-Wilk normality test\n",
    "print(f\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_A = stats.shapiro(calls_A)\n",
    "shapiro_B = stats.shapiro(calls_B)\n",
    "shapiro_C = stats.shapiro(calls_C)\n",
    "print(f\"Group A: p-value = {shapiro_A.pvalue:.4f}\")\n",
    "print(f\"Group B: p-value = {shapiro_B.pvalue:.4f}\")\n",
    "print(f\"Group C: p-value = {shapiro_C.pvalue:.4f}\")\n",
    "\n",
    "# Check if all groups are normally distributed\n",
    "all_normal = all(p >= alpha for p in [shapiro_A.pvalue, shapiro_B.pvalue, shapiro_C.pvalue])\n",
    "\n",
    "if all_normal:\n",
    "    print(\"All groups follow normal distribution -> ANOVA is applicable.\")\n",
    "else:\n",
    "    print(\"At least one group is not normally distributed -> Prefer Kruskal-Wallis test.\")\n",
    "\n",
    "# Test for homogeneity of variances (Levene's test)\n",
    "print(f\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "\n",
    "levene_test = stats.levene(calls_A, calls_B, calls_C)\n",
    "print(f\"Levene's test for homogeneity of variances: p-value = {levene_test.pvalue:.4f}\")\n",
    "\n",
    "if levene_test.pvalue >= alpha:\n",
    "    print(\"Variances are homogeneous\")\n",
    "else:\n",
    "    print(\"Variances are not homogeneous\")\n",
    "\n",
    "# Prepare data for overall tests\n",
    "all_calls = pd.concat([\n",
    "    pd.DataFrame({'group': 'A', 'calls': calls_A}),\n",
    "    pd.DataFrame({'group': 'B', 'calls': calls_B}),\n",
    "    pd.DataFrame({'group': 'C', 'calls': calls_C})\n",
    "])\n",
    "\n",
    "# ANOVA (parametric)\n",
    "anova_result = stats.f_oneway(calls_A, calls_B, calls_C)\n",
    "print(f\"\\n=== ONE-WAY ANOVA RESULTS ===\")\n",
    "print(f\"F-statistic: {anova_result.statistic:.4f}\")\n",
    "print(f\"P-value: {anova_result.pvalue:.4f}\")\n",
    "\n",
    "# Kruskal-Wallis test (non-parametric)\n",
    "kruskal_result = stats.kruskal(calls_A, calls_B, calls_C)\n",
    "print(f\"\\n=== KRUSKAL-WALLIS TEST RESULTS ===\")\n",
    "print(f\"H-statistic: {kruskal_result.statistic:.4f}\")\n",
    "print(f\"P-value: {kruskal_result.pvalue:.4f}\")\n",
    "\n",
    "# Interpretation of overall test\n",
    "if all_normal and levene_test.pvalue >= 0.05:\n",
    "    overall_pvalue = anova_result.pvalue\n",
    "    test_used = \"ANOVA\"\n",
    "else:\n",
    "    overall_pvalue = kruskal_result.pvalue\n",
    "    test_used = \"Kruskal-Wallis\"\n",
    "\n",
    "print(f\"\\n=== OVERALL INTERPRETATION (using {test_used}) ===\")\n",
    "if overall_pvalue < alpha:\n",
    "    print(f\"SIGNIFICANT: p-value = {overall_pvalue:.4f} < alpha = {alpha}\")\n",
    "    print(\"   There are statistically significant differences in teacher solicitation between at least two groups\")\n",
    "else:\n",
    "    print(f\"NOT SIGNIFICANT: p-value = {overall_pvalue:.4f} > alpha = {alpha}\")\n",
    "    print(\"   No statistically significant differences in teacher solicitation between groups\")\n",
    "\n",
    "# POST-HOC TESTS (if significant overall difference)\n",
    "if overall_pvalue < alpha:\n",
    "    print(f\"\\n=== POST-HOC PAIRWISE COMPARISONS ===\")\n",
    "    \n",
    "    # For parametric data: Tukey HSD\n",
    "    if test_used == \"ANOVA\":\n",
    "        print(\"Tukey HSD Post-hoc Test:\")\n",
    "        tukey = pairwise_tukeyhsd(endog=all_calls['calls'], groups=all_calls['group'], alpha=alpha)\n",
    "        print(tukey)\n",
    "        \n",
    "    # For non-parametric data: Mann-Whitney U tests with Bonferroni correction\n",
    "    else:\n",
    "        print(\"Mann-Whitney U tests with Bonferroni correction:\")\n",
    "        pairs = [('A', 'B'), ('A', 'C'), ('B', 'C')]\n",
    "        bonferroni_alpha = alpha / len(pairs)\n",
    "        \n",
    "        for pair in pairs:\n",
    "            group1, group2 = pair\n",
    "            data1 = calls_A if group1 == 'A' else (calls_B if group1 == 'B' else calls_C)\n",
    "            data2 = calls_A if group2 == 'A' else (calls_B if group2 == 'B' else calls_C)\n",
    "            \n",
    "            u_stat, p_value = stats.mannwhitneyu(data1, data2)\n",
    "            adjusted_p = p_value * len(pairs)\n",
    "            significance = \"SIGNIFICANT\" if adjusted_p < alpha else \"not significant\"\n",
    "            \n",
    "            print(f\"  {group1} vs {group2}: p = {p_value:.4f}, adjusted p = {adjusted_p:.4f} -> {significance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c50d916",
   "metadata": {},
   "source": [
    "## 6/ Activity following feedback (Q1.4) [B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de84f87",
   "metadata": {},
   "source": [
    "### 6.1/ Calculation of student activity following feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d4e2c",
   "metadata": {},
   "source": [
    "1/ Following a request to the digital assistant, we categorize the subsequent sequence into four categories:\n",
    "- `progression`: the student managed to progress in the game (first increment of game_progression or reach of next level) without calling the teacher or the digital assistant again\n",
    "- `teacher_call`: the student requested help from the teacher (without having progressed in the game)\n",
    "- `assistant_call`: the student requested help from the digital assistant again (without having progressed in the game)\n",
    "- `other`: other cases, for example, the experiment ends\n",
    "\n",
    "Note that we do not have in the traces the start date of teacher interventions but only the end date. This is why, when we detect a progression in a sequence, we search in the following 120 seconds for a trace of the end of a teacher intervention. If we find one, we reclassify the sequence as `teacher_call`.\n",
    "\n",
    "2/ Moreover, when a progression sequence occurs, we compute:\n",
    "- the progression gain (difference in game_progression)\n",
    "- the sequence of actions before the progression occurred (see `categorize_action()` function bellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for groups B and C\n",
    "groups_BC_interaction = interaction_data[\n",
    "    interaction_data[int_const.GROUP_ID_DATA_KEY].isin([int_const.GROUP_B, int_const.GROUP_C])\n",
    "]\n",
    "\n",
    "# Sort by student and date to analyze sequences\n",
    "groups_BC_interaction = groups_BC_interaction.sort_values([\n",
    "    int_const.GAME_ID_DATA_KEY, \n",
    "    int_const.DATE_DATA_KEY\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# Filter all feedback reception events\n",
    "feedback_events = groups_BC_interaction[\n",
    "    (groups_BC_interaction[int_const.ACTION_DATA_KEY] == int_const.RECEIVED_ACTION) &\n",
    "    (groups_BC_interaction[int_const.OBJECT_DATA_KEY] == int_const.ASSISTANT_HELP_OBJECT)\n",
    "].copy()\n",
    "\n",
    "\n",
    "# Define action categories\n",
    "def categorize_action(row):\n",
    "    action = row[int_const.ACTION_DATA_KEY]\n",
    "    object_name = row[int_const.OBJECT_DATA_KEY]\n",
    "    # Display of the memo\n",
    "    if action == int_const.DISPLAYED_ACTION:\n",
    "        return \"memo_displayed\"\n",
    "    # Copy of feedback content\n",
    "    elif (action == int_const.COPIED_ACTION and \n",
    "          object_name == int_const.ASSISTANT_MESSAGES_SECTION_OBJECT):\n",
    "        return \"feedback_content_copied\"\n",
    "    # Copy of the memo content\n",
    "    elif (action == int_const.COPIED_ACTION and \n",
    "          object_name in [\n",
    "              int_const.BASE_PROGRAM_SECTION_OBJECT,\n",
    "              int_const.BASE_ERROR_SECTION_OBJECT,\n",
    "              int_const.BASE_STRUCTURE_SECTION_OBJECT,\n",
    "              int_const.BASE_COMMENT_SECTION_OBJECT,\n",
    "              int_const.VAR_CREATION_SECTION_OBJECT,\n",
    "              int_const.VAR_MODIFICATION_SECTION_OBJECT,\n",
    "              int_const.VAR_USAGE_SECTION_OBJECT,\n",
    "              int_const.VAR_TYPE_SECTION_OBJECT,\n",
    "              int_const.CONDI_1BRAN_SECTION_OBJECT,\n",
    "              int_const.CONDI_2BRAN_SECTION_OBJECT,\n",
    "              int_const.CONDI_3BRAN_SECTION_OBJECT,\n",
    "              int_const.FOR_SIMPLE_SECTION_OBJECT,\n",
    "              int_const.FOR_COUNTER_0_SECTION_OBJECT,\n",
    "              int_const.FOR_COUNTER_N_SECTION_OBJECT,\n",
    "              int_const.WHILE_SIMPLE_SECTION_OBJECT\n",
    "          ]):\n",
    "        return \"memo_content_copied\"\n",
    "    # Copy of code editor\n",
    "    elif (action == int_const.COPIED_ACTION and \n",
    "          object_name == int_const.CODE_EDITOR_SECTION_OBJECT):\n",
    "        return \"code_editor_copied\"\n",
    "    # Copy of control function\n",
    "    elif (action == int_const.COPIED_ACTION and \n",
    "          object_name == int_const.CONTROL_FUNCTION_SECTION_OBJECT):\n",
    "        return \"control_function_copied\"\n",
    "    # Code paste\n",
    "    elif action == int_const.PASTED_ACTION:\n",
    "        return \"code_pasted\"\n",
    "    # Launch of a correct program\n",
    "    elif (action == int_const.LAUNCHED_ACTION and \n",
    "          object_name in [\n",
    "              int_const.FULLY_EXECUTED_PROGRAM_OBJECT,\n",
    "              int_const.LEVEL_COMPLETED_PROGRAM_OBJECT\n",
    "          ]):\n",
    "        return \"correct_program_launched\"\n",
    "    # Launch of an erroneous program\n",
    "    elif (action == int_const.LAUNCHED_ACTION and \n",
    "          object_name in [\n",
    "              int_const.LEVEL_LOST_PROGRAM_OBJECT,\n",
    "              int_const.TOO_MANY_LINES_ERROR_PROGRAM_OBJECT,\n",
    "              int_const.GAME_ERROR_PROGRAM_OBJECT,\n",
    "              int_const.SYNTACTIC_ERROR_PROGRAM_OBJECT,\n",
    "              int_const.SEMANTIC_ERROR_PROGRAM_OBJECT\n",
    "          ]):\n",
    "        return \"erroneous_program_launched\"\n",
    "    # Launch of a stopped program\n",
    "    elif (action == int_const.LAUNCHED_ACTION and \n",
    "          object_name == int_const.USER_STOPPED_PROGRAM_OBJECT):\n",
    "        return \"stopped_program_launched\"\n",
    "    # Leave to visit a completed level\n",
    "    elif action == int_const.LEAVED_ACTION:\n",
    "        return \"level_leaved\"\n",
    "    # Back from a completed level\n",
    "    elif action in [int_const.RESUMED_ACTION, int_const.RESTARTED_ACTION]:\n",
    "        return \"level_resumed\"\n",
    "    # End of the level (not a real action)\n",
    "    elif action == int_const.ENDED_ACTION:\n",
    "        return \"level_ended\"\n",
    "    # Assistant help called\n",
    "    elif (action == int_const.ASKED_ACTION and \n",
    "          object_name == int_const.ASSISTANT_HELP_OBJECT):\n",
    "        return \"assistant_help_called\"\n",
    "    # Assistant help received\n",
    "    elif (action == int_const.RECEIVED_ACTION and \n",
    "          object_name == int_const.ASSISTANT_HELP_OBJECT):\n",
    "        return \"assistant_help_received\"\n",
    "    # Teacher help received\n",
    "    elif (action == int_const.RECEIVED_ACTION and \n",
    "          object_name == int_const.TEACHER_HELP_OBJECT):\n",
    "        return \"teacher_help_received\"\n",
    "    # Change of speed cursor\n",
    "    elif (action == int_const.CHANGED_ACTION and \n",
    "          object_name == int_const.EXECUTION_SPEED_SLIDE_OBJECT):\n",
    "        return \"speed_cursor_changed\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "\n",
    "feedback_analysis = []\n",
    "# Iterate on each feedback event\n",
    "for _, feedback in feedback_events.iterrows():\n",
    "    game_id = feedback[int_const.GAME_ID_DATA_KEY]\n",
    "    group_id = feedback[int_const.GROUP_ID_DATA_KEY]\n",
    "    feedback_date = feedback[int_const.DATE_DATA_KEY]\n",
    "    feedback_level = feedback[int_const.LEVEL_DATA_KEY]\n",
    "    feedback_progression = feedback[int_const.GAME_PROGRESSION_DATA_KEY]\n",
    "    \n",
    "    # Get student's traces after this feedback\n",
    "    student_traces = groups_BC_interaction[\n",
    "        (groups_BC_interaction[int_const.GAME_ID_DATA_KEY] == game_id) &\n",
    "        (groups_BC_interaction[int_const.DATE_DATA_KEY] > feedback_date)\n",
    "    ]\n",
    "    \n",
    "    actions_after_feedback = []\n",
    "    sequence_outcome = \"other\"  # Default outcome\n",
    "    progression_gain = 0  # Initialize progression gain\n",
    "    progression_date = None  # Track when progression happened\n",
    "    \n",
    "    # Iterate on post-feedback traces\n",
    "    for _, trace in student_traces.iterrows():\n",
    "        current_progression = trace[int_const.GAME_PROGRESSION_DATA_KEY]\n",
    "        current_level = trace[int_const.LEVEL_DATA_KEY]\n",
    "        \n",
    "        # Check for teacher call progression\n",
    "        if (trace[int_const.ACTION_DATA_KEY] == int_const.RECEIVED_ACTION and \n",
    "            trace[int_const.OBJECT_DATA_KEY] == int_const.TEACHER_HELP_OBJECT):\n",
    "            sequence_outcome = \"teacher_call\"\n",
    "            break\n",
    "        \n",
    "        # Check for new assistant call progression\n",
    "        if (trace[int_const.ACTION_DATA_KEY] == int_const.ASKED_ACTION and \n",
    "            trace[int_const.OBJECT_DATA_KEY] == int_const.ASSISTANT_HELP_OBJECT):\n",
    "            sequence_outcome = \"assistant_call\"\n",
    "            break\n",
    "        \n",
    "        # Check if progression increased (in same level) or level increased\n",
    "        progression_increase = (current_level == feedback_level and \n",
    "                               current_progression > feedback_progression)\n",
    "        level_increase = current_level > feedback_level\n",
    "\n",
    "        # Check if progression achieved\n",
    "        if progression_increase or level_increase:\n",
    "            sequence_outcome = \"progression\"\n",
    "            # Calculate progression gain\n",
    "            if level_increase:\n",
    "                progression_gain = 100 - feedback_progression\n",
    "            else:\n",
    "                progression_gain = current_progression - feedback_progression\n",
    "            \n",
    "            # Store the date when progression happened\n",
    "            progression_date = trace[int_const.DATE_DATA_KEY]\n",
    "            \n",
    "            # We break without adding the action that make progression detection\n",
    "            # That's because in the Pyrates trace system, the progression is reported in the next trace\n",
    "            # i.e. each trace report the progression before its action\n",
    "            break\n",
    "        \n",
    "        # Categorize and count all sequence actions\n",
    "        action_type = categorize_action(trace)\n",
    "        # Ignore level_end which is not really an action\n",
    "        if action_type not in [\"level_ended\"]:\n",
    "            actions_after_feedback.append(action_type)\n",
    "    \n",
    "    # Check for teacher call within 120 seconds after detected progression\n",
    "    if sequence_outcome == \"progression\" and progression_date is not None:\n",
    "        # Look for teacher help in the 120 seconds following progression\n",
    "        teacher_help_after_progression = groups_BC_interaction[\n",
    "            (groups_BC_interaction[int_const.GAME_ID_DATA_KEY] == game_id) &\n",
    "            (groups_BC_interaction[int_const.DATE_DATA_KEY] > progression_date) &\n",
    "            (groups_BC_interaction[int_const.DATE_DATA_KEY] <= progression_date + pd.Timedelta(seconds=120)) &\n",
    "            (groups_BC_interaction[int_const.ACTION_DATA_KEY] == int_const.RECEIVED_ACTION) &\n",
    "            (groups_BC_interaction[int_const.OBJECT_DATA_KEY] == int_const.TEACHER_HELP_OBJECT)\n",
    "        ]\n",
    "        \n",
    "        if not teacher_help_after_progression.empty:\n",
    "            sequence_outcome = \"teacher_call\"\n",
    "    \n",
    "    # Store analysis for this feedback event\n",
    "    feedback_analysis.append({\n",
    "        'game_id': game_id,\n",
    "        'group': group_id,\n",
    "        'feedback_level': feedback_level,\n",
    "        'feedback_progression': feedback_progression,\n",
    "        'actions_count': len(actions_after_feedback),\n",
    "        'actions_sequence': actions_after_feedback,\n",
    "        'sequence_outcome': sequence_outcome,\n",
    "        'progression_gain': progression_gain,\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "analysis_df = pd.DataFrame(feedback_analysis)\n",
    "# Export\n",
    "analysis_df.to_excel(f\"../debug/debug_activity_following_feedback.xlsx\")\n",
    "\n",
    "print(f\"Total sequences analyzed: {len(feedback_analysis)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6132e0d8",
   "metadata": {},
   "source": [
    "### 6.2/ Feedback outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf513d5",
   "metadata": {},
   "source": [
    "What is the outcome of the action sequences following the reception of feedback depending on the groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f91599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis for each group\n",
    "for group in [int_const.GROUP_B, int_const.GROUP_C]:\n",
    "    group_data = analysis_df[analysis_df['group'] == group]\n",
    "    \n",
    "    print(f\"\\n=======================================\")\n",
    "    print(f\"GROUP {group} FEEDBACK OUTCOMES\")\n",
    "    print(f\"========================================\")\n",
    "    print(f\"Total feedback sequences: {len(group_data)}\")\n",
    "    \n",
    "    outcome_distribution = group_data['sequence_outcome'].value_counts()\n",
    "    for outcome, count in outcome_distribution.items():\n",
    "        percentage = (count / len(group_data)) * 100\n",
    "        print(f\"   {outcome}: {count} sequences ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2221e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [int_const.GROUP_B, int_const.GROUP_C]\n",
    "\n",
    "# Calculate outcome frequencies across both groups to determine order\n",
    "overall_counts = analysis_df['sequence_outcome'].value_counts()\n",
    "sorted_outcomes = overall_counts.index.tolist()  # Outcomes sorted by frequency\n",
    "\n",
    "# Prepare a DataFrame to store percentages for each group\n",
    "percentage_df = pd.DataFrame(index=sorted_outcomes, columns=groups, dtype=float)\n",
    "\n",
    "for group in groups:\n",
    "    # Filter data for the current group\n",
    "    group_data = analysis_df[analysis_df['group'] == group]\n",
    "    total = len(group_data)\n",
    "    counts = group_data['sequence_outcome'].value_counts()\n",
    "    \n",
    "    for outcome in sorted_outcomes:\n",
    "        # Calculate percentage of each outcome for the group\n",
    "        percentage_df.loc[outcome, group] = (counts.get(outcome, 0) / total) * 100\n",
    "\n",
    "# Parameters for side-by-side bar chart\n",
    "x = np.arange(len(sorted_outcomes))\n",
    "width = 0.4  # width of the bars\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot bars for group B and C\n",
    "bars_B = ax.bar(x - width/2, percentage_df[int_const.GROUP_B], width, label='Group B', color='skyblue')\n",
    "bars_C = ax.bar(x + width/2, percentage_df[int_const.GROUP_C], width, label='Group C', color='salmon')\n",
    "\n",
    "# Set x-axis labels and rotation\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sorted_outcomes, rotation=30, ha='right')\n",
    "\n",
    "# Add axis labels and title\n",
    "ax.set_xlabel(\"Feedback outcome\", fontsize=12)\n",
    "ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "ax.set_ylim(0, 60)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for bars in [bars_B, bars_C]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # offset label slightly above bar\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust layout, save figure and display\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/feedback_outcomes_BC.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8d919",
   "metadata": {},
   "source": [
    "### 6.3/ Progression gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10f284",
   "metadata": {},
   "source": [
    "What is the progression gain resulting of a progression outcome depending on the groups ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20326cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract progression-only data\n",
    "progress_B = analysis_df[(analysis_df['group'] == int_const.GROUP_B) & \n",
    "                         (analysis_df['sequence_outcome'] == 'progression')]\n",
    "\n",
    "progress_C = analysis_df[(analysis_df['group'] == int_const.GROUP_C) & \n",
    "                         (analysis_df['sequence_outcome'] == 'progression')]\n",
    "\n",
    "data_B = progress_B[\"progression_gain\"].dropna()\n",
    "data_C = progress_C[\"progression_gain\"].dropna()\n",
    "\n",
    "# Descriptive statistics\n",
    "mean_B = data_B.mean()\n",
    "mean_C = data_C.mean()\n",
    "std_B = data_B.std()\n",
    "std_C = data_C.std()\n",
    "\n",
    "# Difference in means\n",
    "mean_difference = mean_C - mean_B\n",
    "# Percentage increase (relative to group B)\n",
    "percent_increase = (mean_difference / mean_B) * 100\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group B (n={len(data_B)}): M = {mean_B:.2f}, SD = {std_B:.2f}\")\n",
    "print(f\"Group C (n={len(data_C)}): M = {mean_C:.2f}, SD = {std_C:.2f}\")\n",
    "print(f\".   Difference (C - B): {mean_difference:.2f}\")\n",
    "print(f\".   Percentage increase from B to C: {percent_increase:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "# Normality test\n",
    "print(\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_B = stats.shapiro(data_B)\n",
    "shapiro_C = stats.shapiro(data_C)\n",
    "print(f\"Group B: p-value = {shapiro_B.pvalue:.4f} -> \"\n",
    "        f\"{'normally distributed' if shapiro_B.pvalue >= alpha else 'not normally distributed'}\")\n",
    "print(f\"Group C: p-value = {shapiro_C.pvalue:.4f} -> \"\n",
    "        f\"{'normally distributed' if shapiro_C.pvalue >= alpha else 'not normally distributed'}\")\n",
    "\n",
    "# Levene test\n",
    "print(\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_p = stats.levene(data_B, data_C).pvalue\n",
    "\n",
    "print(f\"Levene p-value = {levene_p:.4f} -> \"\n",
    "        f\"{'variances are similar' if levene_p >= alpha else 'variances differ'}\")\n",
    "\n",
    "print(f\"\\n=== TEST RESULTS ===\")\n",
    "# Choose appropriate test\n",
    "normal_B = shapiro_B.pvalue >= alpha\n",
    "normal_C = shapiro_C.pvalue >= alpha\n",
    "equal_var = levene_p >= alpha\n",
    "\n",
    "if normal_B and normal_C and equal_var:\n",
    "    print(\"Using independent t-test (parametric)\")\n",
    "    stat, p_value = stats.ttest_ind(data_B, data_C, equal_var=True)\n",
    "else:\n",
    "    print(\"Using Mann-Whitney U test (non-parametric)\")\n",
    "    stat, p_value = stats.mannwhitneyu(data_B, data_C, alternative='two-sided')\n",
    "\n",
    "print(f\"Test statistic = {stat:.4f}\")\n",
    "print(f\"P-value = {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"SIGNIFICANT difference: p = {p_value:.4f} < {alpha}\")\n",
    "else:\n",
    "    print(f\"No significant difference: p = {p_value:.4f} >= {alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58950dcd",
   "metadata": {},
   "source": [
    "### 6.4/ Number of actions before progression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e4284",
   "metadata": {},
   "source": [
    "How many actions do students need to achieve a progression in the game following feedback depending on the groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract progression-only data\n",
    "progress_B = analysis_df[(analysis_df['group'] == int_const.GROUP_B) & \n",
    "                         (analysis_df['sequence_outcome'] == 'progression')]\n",
    "\n",
    "progress_C = analysis_df[(analysis_df['group'] == int_const.GROUP_C) & \n",
    "                         (analysis_df['sequence_outcome'] == 'progression')]\n",
    "\n",
    "data_B = progress_B[\"actions_count\"].dropna()\n",
    "data_C = progress_C[\"actions_count\"].dropna()\n",
    "\n",
    "# Descriptive statistics\n",
    "mean_B = data_B.mean()\n",
    "mean_C = data_C.mean()\n",
    "std_B = data_B.std()\n",
    "std_C = data_C.std()\n",
    "\n",
    "# Difference in means\n",
    "mean_difference = mean_C - mean_B\n",
    "# Percentage increase (relative to group B)\n",
    "percent_increase = (mean_difference / mean_B) * 100\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group B (n={len(data_B)}): M = {mean_B:.2f}, SD = {std_B:.2f}\")\n",
    "print(f\"Group C (n={len(data_C)}): M = {mean_C:.2f}, SD = {std_C:.2f}\")\n",
    "print(f\".   Difference (C - B): {mean_difference:.2f}\")\n",
    "print(f\".   Percentage increase from B to C: {percent_increase:.2f}%\")\n",
    "\n",
    "alpha = 0.05\n",
    "# Normality test\n",
    "print(\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "shapiro_B = stats.shapiro(data_B)\n",
    "shapiro_C = stats.shapiro(data_C)\n",
    "print(f\"Group B: p-value = {shapiro_B.pvalue:.4f} -> \"\n",
    "        f\"{'normally distributed' if shapiro_B.pvalue >= 0.05 else 'not normally distributed'}\")\n",
    "print(f\"Group C: p-value = {shapiro_C.pvalue:.4f} -> \"\n",
    "        f\"{'normally distributed' if shapiro_C.pvalue >= 0.05 else 'not normally distributed'}\")\n",
    "\n",
    "# Levene test\n",
    "print(\"\\n=== HOMOGENEITY OF VARIANCES (Levene) ===\")\n",
    "levene_p = stats.levene(data_B, data_C).pvalue\n",
    "\n",
    "print(f\"Levene p-value = {levene_p:.4f} -> \"\n",
    "        f\"{'variances are similar' if levene_p >= 0.05 else 'variances differ'}\")\n",
    "\n",
    "print(f\"\\n=== TEST RESULTS ===\")\n",
    "# Choose appropriate test\n",
    "normal_B = shapiro_B.pvalue >= alpha\n",
    "normal_C = shapiro_C.pvalue >= alpha\n",
    "equal_var = levene_p >= alpha\n",
    "\n",
    "if normal_B and normal_C and equal_var:\n",
    "    print(\"Using independent t-test (parametric)\")\n",
    "    stat, p_value = stats.ttest_ind(data_B, data_C, equal_var=True)\n",
    "else:\n",
    "    print(\"Using Mann-Whitney U test (non-parametric)\")\n",
    "    stat, p_value = stats.mannwhitneyu(data_B, data_C, alternative='two-sided')\n",
    "\n",
    "print(f\"Test statistic = {stat:.4f}\")\n",
    "print(f\"P-value = {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"SIGNIFICANT difference: p = {p_value:.4f} < {alpha}\")\n",
    "else:\n",
    "    print(f\"No significant difference: p = {p_value:.4f} >= {alpha}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0e688",
   "metadata": {},
   "source": [
    "### 6.5/ Action distribution in progression sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93665be",
   "metadata": {},
   "source": [
    "What type of actions do students perform before achieving a progression in the game following feedback depending on the groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91443377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis for each group\n",
    "for group in [int_const.GROUP_B, int_const.GROUP_C]:\n",
    "    group_data = analysis_df[analysis_df['group'] == group]\n",
    "    print(f\"\\n=============================\")\n",
    "    print(f\"GROUP {group} ACTION DISTRIBUTION\")\n",
    "    print(f\"=============================\")\n",
    "    \n",
    "    # Analysis for progression outcomes\n",
    "    progression_data = group_data[group_data['sequence_outcome'] == 'progression']\n",
    "    \n",
    "    if len(progression_data) > 0:\n",
    "        all_actions = []\n",
    "        for action_list in progression_data['actions_sequence']:\n",
    "            all_actions.extend(action_list)\n",
    "        action_counts = pd.Series(all_actions).value_counts()\n",
    "        total_actions = len(all_actions)\n",
    "            \n",
    "        for action, count in action_counts.head(10).items():  # Top 10 actions\n",
    "            percentage = (count / total_actions) * 100\n",
    "            print(f\"   {action}: {count} times ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"   Total actions analyzed: {total_actions}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5036728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups to compare\n",
    "groups = [int_const.GROUP_B, int_const.GROUP_C]\n",
    "\n",
    "# Collect all actions across both groups during progression to determine overall frequency\n",
    "all_actions_overall = []\n",
    "for group in groups:\n",
    "    group_data = analysis_df[(analysis_df['group'] == group) & (analysis_df['sequence_outcome'] == 'progression')]\n",
    "    for action_list in group_data['actions_sequence']:\n",
    "        all_actions_overall.extend(action_list)\n",
    "\n",
    "# Get top 6 actions sorted by overall frequency\n",
    "overall_counts = pd.Series(all_actions_overall).value_counts()\n",
    "sorted_actions = overall_counts.head(6).index.tolist()  # Keep only top 6 actions\n",
    "\n",
    "# Prepare a DataFrame to store percentages for each group\n",
    "percentage_df = pd.DataFrame(index=sorted_actions, columns=groups, dtype=float)\n",
    "\n",
    "for group in groups:\n",
    "    # Filter progression sequences for the current group\n",
    "    group_data = analysis_df[(analysis_df['group'] == group) & (analysis_df['sequence_outcome'] == 'progression')]\n",
    "    \n",
    "    # Flatten all actions\n",
    "    all_actions = []\n",
    "    for action_list in group_data['actions_sequence']:\n",
    "        all_actions.extend(action_list)\n",
    "    \n",
    "    total_actions = len(all_actions)\n",
    "    action_counts = pd.Series(all_actions).value_counts()\n",
    "    \n",
    "    # Calculate percentages for each action\n",
    "    for action in sorted_actions:\n",
    "        percentage_df.loc[action, group] = (action_counts.get(action, 0) / total_actions) * 100 if total_actions > 0 else 0\n",
    "\n",
    "# Parameters for side-by-side bar chart\n",
    "x = np.arange(len(sorted_actions))\n",
    "width = 0.40  # width of the bars\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot bars for group B and C\n",
    "bars_B = ax.bar(x - width/2, percentage_df['B'], width, label='Group B', color='skyblue')\n",
    "bars_C = ax.bar(x + width/2, percentage_df['C'], width, label='Group C', color='salmon')\n",
    "\n",
    "# Set x-axis labels and rotation\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sorted_actions, rotation=30, ha='right')\n",
    "\n",
    "# Add axis labels and title\n",
    "ax.set_xlabel(\"Action type\", fontsize=12)\n",
    "ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, 37)\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for bars in [bars_B, bars_C]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # offset label slightly above bar\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust layout, save figure, and display\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/action_types_BC.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc923a",
   "metadata": {},
   "source": [
    "### 6.6/ Action patterns in progression sequences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da84f7",
   "metadata": {},
   "source": [
    "What are the most frequent action patterns in progression sequences depending on groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9821b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_display = 10\n",
    "# Filter only progression events for groups B and C\n",
    "progress_B = analysis_df[\n",
    "    (analysis_df['group'] == int_const.GROUP_B) &\n",
    "    (analysis_df['sequence_outcome'] == 'progression')\n",
    "]\n",
    "\n",
    "progress_C = analysis_df[\n",
    "    (analysis_df['group'] == int_const.GROUP_C) &\n",
    "    (analysis_df['sequence_outcome'] == 'progression')\n",
    "]\n",
    "\n",
    "# Extract full action sequences as tuples (so they are hashable)\n",
    "sequences_B = progress_B['actions_sequence'].apply(tuple)\n",
    "sequences_C = progress_C['actions_sequence'].apply(tuple)\n",
    "\n",
    "# Count most common sequences for each group (top n)\n",
    "top_sequences_B = sequences_B.value_counts().head(top_n_display)\n",
    "top_sequences_C = sequences_C.value_counts().head(top_n_display)\n",
    "\n",
    "# Compute total for percentages\n",
    "total_B = len(sequences_B)\n",
    "total_C = len(sequences_C)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n==================================\")\n",
    "print(f\"Top {top_n_display} Action Sequences  Group B\")\n",
    "print(f\"==================================\")\n",
    "for seq, count in top_sequences_B.items():\n",
    "    pct = (count / total_B) * 100\n",
    "    print(f\"- {list(seq)}  {count} occurrences ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n==================================\")\n",
    "print(f\"Top {top_n_display} Action Sequences  Group C\")\n",
    "print(f\"==================================\")\n",
    "for seq, count in top_sequences_C.items():\n",
    "    pct = (count / total_C) * 100\n",
    "    print(f\"- {list(seq)}  {count} occurrences ({pct:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ee5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_plot = 6\n",
    "\n",
    "# Count most common sequences for each group (TOP6 for plotting)\n",
    "top_sequences_B_plot = sequences_B.value_counts().head(top_n_plot)\n",
    "top_sequences_C_plot = sequences_C.value_counts().head(top_n_plot)\n",
    "\n",
    "# Labels and percentages for plotting\n",
    "seq_labels_B = ['\\n'.join(seq) for seq in top_sequences_B_plot.index]\n",
    "seq_labels_C = ['\\n'.join(seq) for seq in top_sequences_C_plot.index]\n",
    "\n",
    "percent_B = [(count / total_B) * 100 for count in top_sequences_B_plot.values]\n",
    "percent_C = [(count / total_C) * 100 for count in top_sequences_C_plot.values]\n",
    "\n",
    "# X positions\n",
    "x_B = np.arange(len(top_sequences_B_plot))\n",
    "x_C = np.arange(len(top_sequences_C_plot))\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot bars\n",
    "bars_B = ax.bar(x_B - width/2, percent_B, width, label='Group B', color='skyblue')\n",
    "bars_C = ax.bar(x_C + width/2, percent_C, width, label='Group C', color='salmon')\n",
    "\n",
    "# X-axis labels\n",
    "ax.set_xticks(np.arange(top_n_plot))\n",
    "labels_combined = seq_labels_B + seq_labels_C\n",
    "ax.set_xticklabels(labels_combined[:top_n_plot], rotation=30, ha='right')\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xlabel(\"Top Action Sequences\", fontsize=12)\n",
    "ax.set_ylabel(\"Percentage (%)\", fontsize=12)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_ylim(0, max(max(percent_B), max(percent_C))+2)\n",
    "\n",
    "# Add percentage labels\n",
    "for bars in [bars_B, bars_C]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/top_action_sequences_BC.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
