{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "![Logo Pyrates LLM](../assets/pyratesllm_logo_500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# **Notebook#01 : Data cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This notebook performs cleaning and filtering of data collected from the Pyrates LLM experimental study, which includes:\n",
    "\n",
    "1. **Interaction traces** from the Pyrates application\n",
    "2. **Pre-test and post-test questionnaire** from the online survey tool\n",
    "\n",
    "## Input\n",
    "- `data/raw/raw_data_interaction_traces.csv`\n",
    "- `data/raw/raw_data_pre_test_BOU_STA.csv`\n",
    "- `data/raw/raw_data_pre_test_LIP.csv`\n",
    "- `data/raw/raw_data_pre_test_LJS.csv`\n",
    "- `data/raw/raw_data_pre_test_PVA.csv`\n",
    "- `data/raw/raw_data_post_test_BOU_STA.csv`\n",
    "- `data/raw/raw_data_post_test_LIP.csv`\n",
    "- `data/raw/raw_data_post_test_LJS.csv`\n",
    "- `data/raw/raw_data_post_test_PVA.csv`\n",
    "\n",
    "\n",
    "## Output (manual checking)\n",
    "- `data/cleaned/cleaned_data_interaction_traces.xlsx`\n",
    "- `data/cleaned/cleaned_data_pre_test.xlsx`\n",
    "- `data/cleaned/cleaned_data_post_test.xlsx`\n",
    "  \n",
    "## Output (following notebooks analyses)\n",
    "- `data/interim/interaction_data.pkl`\n",
    "- `data/interim/pre_test_data.pkl`\n",
    "- `data/interim/post_test_data.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1/ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import students_constants as stu_const\n",
    "import interaction_constants as int_const\n",
    "import tests_constants  as tes_const\n",
    "import session_date_constants as ses_const\n",
    "\n",
    "# External\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2/ Manual work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2.1/ Get raw data from interaction traces database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The data is extracted from the `JOINED_TRACES` SQL view defined as follows :\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    `trace`.`id` AS `id`,\n",
    "    `trace`.`date` AS `date`,\n",
    "    `trace`.`game_id` AS `game_id`,\n",
    "    `trace`.`level_id` AS `level_id`,\n",
    "    `trace`.`game_time` AS `game_time`,\n",
    "    `trace`.`progression` AS `progression`,\n",
    "    `action`.`name` AS `action_name`,\n",
    "    `object`.`name` AS `object_name`,\n",
    "    `trace`.`duration` AS `duration`,\n",
    "    `trace`.`code` AS `code`,\n",
    "    `trace`.`value` AS `value`,\n",
    "    `reason`.`name` AS `reason_name`,\n",
    "    `trace`.`error_message` AS `error_message`,\n",
    "    `trace`.`x_pos` AS `x_pos`,\n",
    "    `trace`.`y_pos` AS `y_pos`,\n",
    "    `trace`.`flipped` AS `flipped`,\n",
    "    `trace`.`owned_key` AS `owned_key`\n",
    "FROM \n",
    "    (((`trace` LEFT JOIN `action` on(`trace`.`action_id` = `action`.`id`)) \n",
    "        LEFT JOIN `object` on(`trace`.`object_id` = `object`.`id`))\n",
    "        LEFT JOIN `reason` on(`trace`.`reason_id` = `reason`.`id`))\n",
    "ORDER BY `trace`.`date` DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "**Actions**:\n",
    "1. Filter interaction traces over the experimentation period\n",
    "```sql\n",
    "SELECT * FROM `JOINED_TRACES` WHERE date > '2025-10-06 00:00:00' AND date < '2025-12-19 23:59:59';\n",
    "```\n",
    "2. Export as `.csv` files :\n",
    "- `raw_data_interaction_traces.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.2/ Get raw data from the online survey tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**Actions**:\n",
    "1. TODO SL ?\n",
    "2. Export as `.csv` files :\n",
    "- `data/raw/raw_data_pre_test_BOU_STA.csv`\n",
    "- `data/raw/raw_data_pre_test_LIP.csv`\n",
    "- `data/raw/raw_data_pre_test_LJS.csv`\n",
    "- `data/raw/raw_data_pre_test_PVA.csv`\n",
    "- `data/raw/raw_data_post_test_BOU_STA.csv`\n",
    "- `data/raw/raw_data_post_test_LIP.csv`\n",
    "- `data/raw/raw_data_post_test_LJS.csv`\n",
    "- `data/raw/raw_data_post_test_PVA.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3/ Data fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 3.1/ Interaction traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load interaction traces data\n",
    "interaction_data = pd.read_csv(\"../data/raw/raw_data_interaction_traces.csv\",sep=\";\",header = 0, encoding=\"latin1\")\n",
    "# interaction_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 3.2/ Pre and post-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to normalize pre and post-tests columns name which are complex and verbose\n",
    "# (makes dataframe fusion more easy)\n",
    "def normalize_column_name(col):\n",
    "    # Remove accents\n",
    "    col = unidecode.unidecode(col)\n",
    "    # Lowercase\n",
    "    col = col.lower()\n",
    "    # Replace special apostrophes with '\n",
    "    col = col.replace(\"’\", \"'\")\n",
    "    # Replace spaces by underscore\n",
    "    col = col.replace(\" \", \"_\")\n",
    "    # Keep only alphanumeric + underscores\n",
    "    col = re.sub(r\"[^a-z0-9_]\", \"\", col)\n",
    "    # Remove duplicate underscores\n",
    "    col = re.sub(r\"_+\", \"_\", col)\n",
    "    # Remove leading/trailing underscores\n",
    "    col = col.strip(\"_\")\n",
    "    # Remove explicit unwanted parts\n",
    "    forbidden_parts = [\"_p2xxr\", \"_p2xpxr\", \"_314\", \"_p314\"]\n",
    "    for bad in forbidden_parts:\n",
    "        col = col.replace(bad, \"\")\n",
    "    return col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Load pre-test datasets for each school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_data_BOU_STA = pd.read_csv(\"../data/raw/raw_data_pre_test_BOU_STA.csv\",sep=\"\\t\",header = 0, encoding=\"latin1\")\n",
    "pre_test_data_BOU_STA.columns = [normalize_column_name(c) for c in pre_test_data_BOU_STA.columns]\n",
    "# pre_test_data_BOU_STA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_data_LJS = pd.read_csv(\"../data/raw/raw_data_pre_test_LJS.csv\",sep=\",\",header = 0, encoding=\"utf-8\")\n",
    "pre_test_data_LJS.columns = [normalize_column_name(c) for c in pre_test_data_LJS.columns]\n",
    "# pre_test_data_LJS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_data_PVA = pd.read_csv(\"../data/raw/raw_data_pre_test_PVA.csv\",sep=\"\\t\",header = 0, encoding=\"latin1\")\n",
    "pre_test_data_PVA.columns = [normalize_column_name(c) for c in pre_test_data_PVA.columns]\n",
    "# pre_test_data_PVA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_data_LIP = pd.read_csv(\"../data/raw/raw_data_pre_test_LIP.csv\",sep=\"\\t\",header = 0, encoding=\"latin1\")\n",
    "pre_test_data_LIP.columns = [normalize_column_name(c) for c in pre_test_data_PVA.columns]\n",
    "# pre_test_data_LIP.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_data = pd.concat(\n",
    "    [pre_test_data_BOU_STA, pre_test_data_LJS, pre_test_data_PVA,pre_test_data_LIP],\n",
    "    ignore_index=True\n",
    ")\n",
    "# pre_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Load post-test datasets for each school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_test_data_BOU_STA = pd.read_csv(\"../data/raw/raw_data_post_test_BOU_STA.csv\",sep=\"\\t\",header = 0, encoding=\"latin1\")\n",
    "post_test_data_BOU_STA.columns = [normalize_column_name(c) for c in post_test_data_BOU_STA.columns]\n",
    "# post_test_data_BOU_STA.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_test_data_LJS = pd.read_csv(\"../data/raw/raw_data_post_test_LJS.csv\",sep=\",\",header = 0, encoding=\"utf-8\")\n",
    "post_test_data_LJS.columns = [normalize_column_name(c) for c in post_test_data_LJS.columns]\n",
    "# post_test_data_LJS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_test_data_PVA = pd.read_csv(\"../data/raw/raw_data_post_test_PVA.csv\",sep=\"\\t\",header = 0, encoding=\"latin1\")\n",
    "post_test_data_PVA.columns = [normalize_column_name(c) for c in post_test_data_PVA.columns]\n",
    "# post_test_data_PVA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_test_data_LIP = pd.read_csv(\"../data/raw/raw_data_post_test_LIP.csv\",sep=\"\\t\",header = 0, encoding=\"latin1\")\n",
    "post_test_data_LIP.columns = [normalize_column_name(c) for c in post_test_data_PVA.columns]\n",
    "# post_test_data_LIP.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_test_data = pd.concat(\n",
    "    [post_test_data_BOU_STA, post_test_data_LJS, post_test_data_PVA,post_test_data_LIP],\n",
    "    ignore_index=True\n",
    ")\n",
    "# post_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 4/ Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 4.2/ Interaction traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Filter and reorder columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "See `src/interaction_constants.py` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data=interaction_data[int_const.INTERACTION_DATA_KEYS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Set data to the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date : object > datetime\n",
    "interaction_data[int_const.DATE_DATA_KEY] = pd.to_datetime(interaction_data[int_const.DATE_DATA_KEY], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "# duration : float > Int64 (nullable)\n",
    "interaction_data[int_const.DURATION_DATA_KEY] = interaction_data[int_const.DURATION_DATA_KEY].astype(\"Int64\")\n",
    "# value : float > Int64 (nullable)\n",
    "interaction_data[int_const.VALUE_DATA_KEY] = interaction_data[int_const.VALUE_DATA_KEY].astype(\"Int64\")\n",
    "# x_pos : float > Int64 (nullable)\n",
    "interaction_data[int_const.X_POS_DATA_KEY] = interaction_data[int_const.X_POS_DATA_KEY].astype(\"Int64\")\n",
    "# y_pos : float > Int64 (nullable)\n",
    "interaction_data[int_const.Y_POS_DATA_KEY] = interaction_data[int_const.Y_POS_DATA_KEY].astype(\"Int64\")\n",
    "# flipped : float > boolean (nullable)\n",
    "interaction_data[int_const.FLIPPED_DATA_KEY] = interaction_data[int_const.Y_POS_DATA_KEY].astype(\"boolean\")\n",
    "# owned_key : float > boolean (nullable)\n",
    "interaction_data[int_const.OWNED_KEY_DATA_KEY] = interaction_data[int_const.OWNED_KEY_DATA_KEY].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interaction_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Remove unsupported characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_illegal_char(s):\n",
    "    if isinstance(s, str):\n",
    "        return s.replace('\\x19', '')\n",
    "    return s\n",
    "\n",
    "interaction_data[int_const.CODE_DATA_KEY] = interaction_data[int_const.CODE_DATA_KEY].apply(remove_illegal_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Timestamp changes due to experimental problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Chronological anomalies are present in the traces due to an experimental incident during session BOU_2_5 Session 1: computer's internal clock was set back by approximately 7 minutes (472 seconds) for 15 students, impacting the trace data (see details below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEMATIC_GAMES = [\n",
    "    { \"game_id\" : \"PnMK39E\",\"last_correct_id\" : \"16420\"},\n",
    "    { \"game_id\" : \"1y9zZYa\",\"last_correct_id\" : \"16720\"},\n",
    "    { \"game_id\" : \"CCbUYFz\",\"last_correct_id\" : \"16379\"},\n",
    "    { \"game_id\" : \"Arxwr9G\",\"last_correct_id\" : \"16193\"},\n",
    "    { \"game_id\" : \"guH7Ye8\",\"last_correct_id\" : \"16997\"},\n",
    "    { \"game_id\" : \"W7Rp7uy\",\"last_correct_id\" : \"17108\"},\n",
    "    { \"game_id\" : \"fu46Vr2\",\"last_correct_id\" : \"17993\"},\n",
    "    { \"game_id\" : \"FPJCjd3\",\"last_correct_id\" : \"16809\"},\n",
    "    { \"game_id\" : \"AyVKNE4\",\"last_correct_id\" : \"17639\"},\n",
    "    { \"game_id\" : \"p6UCEdQ\",\"last_correct_id\" : \"15901\"},\n",
    "    { \"game_id\" : \"SzebmX3\",\"last_correct_id\" : \"17463\"},\n",
    "    { \"game_id\" : \"7Kq3hhp\",\"last_correct_id\" : \"16654\"},\n",
    "    { \"game_id\" : \"CmQ3bi3\",\"last_correct_id\" : \"16131\"},\n",
    "    { \"game_id\" : \"rVUtbKs\",\"last_correct_id\" : \"16142\"},\n",
    "    { \"game_id\" : \"PuDNWgY\",\"last_correct_id\" : \"16063\"},\n",
    "]\n",
    "TIME_DELTA = 472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct timestamps for problematic games:\n",
    "# - For each game_id in PROBLEMATIC_GAMES\n",
    "#    - For trace ids < last_correct_id: subtract 472 seconds from date\n",
    "total_corrected_traces = 0\n",
    "for game_info in PROBLEMATIC_GAMES:\n",
    "    game_id = game_info[\"game_id\"]\n",
    "    last_correct_id = int(game_info[\"last_correct_id\"])\n",
    "    # Find traces for this game_id with id < last_correct_id\n",
    "    mask = (\n",
    "        (interaction_data[int_const.GAME_ID_DATA_KEY] == game_id) & \n",
    "        (interaction_data[int_const.ID_DATA_KEY] < last_correct_id)\n",
    "    )\n",
    "    traces_to_correct = interaction_data[mask]\n",
    "    if len(traces_to_correct) > 0:\n",
    "        # Subtract TIME_DELTA seconds\n",
    "        interaction_data.loc[mask, int_const.DATE_DATA_KEY] = (\n",
    "           interaction_data.loc[mask, int_const.DATE_DATA_KEY] - \n",
    "            pd.to_timedelta(TIME_DELTA, unit='s')\n",
    "        )\n",
    "        total_corrected_traces +=len(traces_to_correct)\n",
    "    else:\n",
    "        print(f\"No traces to correct\")\n",
    "print(f\"Total corrected traces : {total_corrected_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "For game_id \"CVtd56h\", traces before id 66160 are late by one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (interaction_data[int_const.GAME_ID_DATA_KEY] == \"CVtd56h\") & \\\n",
    "       (interaction_data[int_const.ID_DATA_KEY] <= 66160)\n",
    "\n",
    "interaction_data.loc[mask, int_const.DATE_DATA_KEY] = (\n",
    "    pd.to_datetime(interaction_data.loc[mask, int_const.DATE_DATA_KEY]) \n",
    "    + pd.Timedelta(hours=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "For game_id \"J3Ua1SU\", traces before id 60657 are head by one hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (interaction_data[int_const.GAME_ID_DATA_KEY] == \"J3Ua1SU\") & \\\n",
    "       (interaction_data[int_const.ID_DATA_KEY] <= 60657)\n",
    "\n",
    "interaction_data.loc[mask, int_const.DATE_DATA_KEY] = (\n",
    "    pd.to_datetime(interaction_data.loc[mask, int_const.DATE_DATA_KEY]) \n",
    "    - pd.Timedelta(hours=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "For game_id \"Pu9T7qe\", traces before id 68779 are late by one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (interaction_data[int_const.GAME_ID_DATA_KEY] == \"Pu9T7qe\") & \\\n",
    "       (interaction_data[int_const.ID_DATA_KEY] <= 68779)\n",
    "\n",
    "interaction_data.loc[mask, int_const.DATE_DATA_KEY] = (\n",
    "    pd.to_datetime(interaction_data.loc[mask, int_const.DATE_DATA_KEY]) \n",
    "    + pd.Timedelta(hours=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "For game_id \"e5wqMLP\", traces before id 68644 are late by one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (interaction_data[int_const.GAME_ID_DATA_KEY] == \"e5wqMLP\") & \\\n",
    "       (interaction_data[int_const.ID_DATA_KEY] <= 68644)\n",
    "\n",
    "interaction_data.loc[mask, int_const.DATE_DATA_KEY] = (\n",
    "    pd.to_datetime(interaction_data.loc[mask, int_const.DATE_DATA_KEY]) \n",
    "    + pd.Timedelta(hours=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "For game_id \"k18if8F\", traces before id 66402 are late by one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (interaction_data[int_const.GAME_ID_DATA_KEY] == \"k18if8F\") & \\\n",
    "       (interaction_data[int_const.ID_DATA_KEY] <= 66402)\n",
    "\n",
    "interaction_data.loc[mask, int_const.DATE_DATA_KEY] = (\n",
    "    pd.to_datetime(interaction_data.loc[mask, int_const.DATE_DATA_KEY]) \n",
    "    + pd.Timedelta(hours=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### 4.3/ Pre and post-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Removal of technical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_pre_test = [\n",
    "    0,  # ID de la réponse\n",
    "    2,  # Dernière page\n",
    "    3,  # Langue de départ\n",
    "    4,  # Tête de série\n",
    "    6,  # Date de la dernière action\n",
    "    7,  # Quel est le code de ton groupe ?\n",
    "    18, # Temps total\n",
    "    19, # Durée pour le groupe : Information\n",
    "    20, # Durée pour la question: I1\n",
    "    21, # Durée pour la question: I2\n",
    "    22, # Durée pour le groupe : Test de connaissances en Scratch\n",
    "    23, # Durée pour la question: Q1\n",
    "    24, # Durée pour la question: Q2\n",
    "    25, # Durée pour la question: Q3\n",
    "    26, # Durée pour la question: Q4\n",
    "    27, # Durée pour la question: Q5\n",
    "    28, # Durée pour la question: Q6\n",
    "    29, # Durée pour la question: Q7\n",
    "    30, # Durée pour la question: Q8\n",
    "    31, # Durée pour la question: Q9\n",
    "]\n",
    "pre_test_data = pre_test_data.drop(pre_test_data.columns[cols_to_drop_pre_test], axis=1)\n",
    "# pre_test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_post_test = [\n",
    "    0,  # ID de la réponse\n",
    "    2,  # Dernière page\n",
    "    3,  # Langue de départ\n",
    "    4,  # Tête de série\n",
    "    6,  # Date de la dernière action\n",
    "    7,  # Quel est le code de ton groupe ?\n",
    "    29, # Temps total\n",
    "    30, # Durée pour le groupe : Informations\n",
    "    31, # Durée pour la question: I1\n",
    "    32, # Durée pour la question: I2\n",
    "    33, # Durée pour le groupe : Test de connaissances en Python\n",
    "    34, # Durée pour la question: Q1\n",
    "    35, # Durée pour la question: Q2\n",
    "    36, # Durée pour la question: Q3\n",
    "    37, # Durée pour la question: Q4\n",
    "    38, # Durée pour la question: Q5\n",
    "    39, # Durée pour la question: Q6\n",
    "    40, # Durée pour la question: Q7\n",
    "    41, # Durée pour la question: Q8\n",
    "    42, # Durée pour la question: Q9\n",
    "    43, # Durée pour le groupe : Avis sur les aides du perroquet assistant numérique \n",
    "    44, # Durée pour la question: A1\n",
    "    45, # Durée pour la question: A2\n",
    "    46, # Durée pour la question: A9\n",
    "    47, # Durée pour la question: A4\n",
    "    48, # Durée pour la question: A3\n",
    "    49, # Durée pour la question: G03Q17\n",
    "    50, # Durée pour la question: G03Q18\n",
    "    51, # Durée pour le groupe : Avis sur le jeu\n",
    "    52, # Durée pour la question: G04Q19\n",
    "    53, # Durée pour la question: G04Q20\n",
    "    54, # Durée pour la question: G04Q21\n",
    "\n",
    "]\n",
    "post_test_data = post_test_data.drop(post_test_data.columns[cols_to_drop_post_test], axis=1)\n",
    "# post_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### Rename and reorder revelant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "See `src/tests_constants.py` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "pre_test_data.columns = [\n",
    "    tes_const.T2_KEY, tes_const.T1_KEY,\n",
    "    tes_const.STUDENT_ID_KEY,\n",
    "    tes_const.Q1_KEY,tes_const.Q2_KEY, tes_const.Q3_KEY, tes_const.Q4_KEY, tes_const.Q5_KEY, tes_const.Q6_KEY, tes_const.Q7_KEY, tes_const.Q8_KEY, tes_const.Q9_KEY,\n",
    "]\n",
    "# Reorder\n",
    "pre_test_data = pre_test_data[tes_const.PRE_TEST_KEYS]\n",
    "# pre_test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "post_test_data.columns = [\n",
    "    tes_const.T2_KEY, tes_const.T1_KEY,\n",
    "    tes_const.STUDENT_ID_KEY,\n",
    "    tes_const.Q1_KEY, tes_const.Q2_KEY, tes_const.Q3_KEY, tes_const.Q4_KEY, tes_const.Q5_KEY, tes_const.Q6_KEY, tes_const.Q7_KEY, tes_const.Q8_KEY, tes_const.Q9_KEY,\n",
    "    tes_const.QA_KEY, tes_const.QB_KEY, tes_const.QC_KEY, tes_const.QD_KEY, tes_const.QE_KEY, tes_const.QF_KEY, tes_const.QG_KEY, \n",
    "    tes_const.QH_KEY, \n",
    "    tes_const.QI_KEY, tes_const.QJ_KEY, \n",
    "    tes_const.QK_KEY, \n",
    "]\n",
    "# Reorder\n",
    "post_test_data = post_test_data[tes_const.POST_TEST_KEYS]\n",
    "# post_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Set data to the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  _student_id : float > int\n",
    "pre_test_data[tes_const.STUDENT_ID_KEY] = pre_test_data[tes_const.STUDENT_ID_KEY].astype(int)\n",
    "# _T1 : object > datetime\n",
    "pre_test_data[tes_const.T1_KEY] = pd.to_datetime(pre_test_data[tes_const.T1_KEY], format=\"%d/%m/%Y %H:%M\")\n",
    "# _T2 : object > datetime\n",
    "pre_test_data[tes_const.T2_KEY] = pd.to_datetime(pre_test_data[tes_const.T2_KEY], format=\"%d/%m/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre_test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  _student_id : float > int\n",
    "post_test_data[tes_const.STUDENT_ID_KEY] = post_test_data[tes_const.STUDENT_ID_KEY].astype(int)\n",
    "#  _QA : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QA_KEY] = post_test_data[tes_const.QA_KEY].astype(\"Int64\")\n",
    "#  _QB : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QB_KEY] = post_test_data[tes_const.QB_KEY].astype(\"Int64\")\n",
    "#  _QC : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QC_KEY] = post_test_data[tes_const.QC_KEY].astype(\"Int64\")\n",
    "#  _QD : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QD_KEY] = post_test_data[tes_const.QD_KEY].astype(\"Int64\")\n",
    "#  _QE : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QE_KEY] = post_test_data[tes_const.QE_KEY].astype(\"Int64\")\n",
    "#  _QI : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QI_KEY] = post_test_data[tes_const.QI_KEY].astype(\"Int64\")\n",
    "#  _QJ : float > Int64 (nullable)\n",
    "post_test_data[tes_const.QJ_KEY] = post_test_data[tes_const.QJ_KEY].astype(\"Int64\")\n",
    "# _T1 : object > datetime\n",
    "post_test_data[tes_const.T1_KEY] = pd.to_datetime(post_test_data[tes_const.T1_KEY], format=\"%d/%m/%Y %H:%M\")\n",
    "# _T2 : object > datetime\n",
    "post_test_data[tes_const.T2_KEY] = pd.to_datetime(post_test_data[tes_const.T2_KEY], format=\"%d/%m/%Y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(post_test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Correct Q4 columns values (bug in the form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "For the values in column Q4: adding \"A)\", \"B)\", \"C)\", etc. before the answer text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS_MAPPING = {\n",
    "    \"c\"  : \"A) c\",\n",
    "    \"2\"  : \"B) 2\",\n",
    "    \"9\"  : \"C) 9\",\n",
    "    \"12\" : \"D) 12\",\n",
    "    \"14\" : \"E) 14\",\n",
    "}\n",
    "# Keep the current value if not present in the mapping\n",
    "pre_test_data[tes_const.Q4_KEY] = pre_test_data[tes_const.Q4_KEY].map(ANS_MAPPING).fillna(pre_test_data[tes_const.Q4_KEY])\n",
    "post_test_data[tes_const.Q4_KEY] = post_test_data[tes_const.Q4_KEY].map(ANS_MAPPING).fillna(post_test_data[tes_const.Q4_KEY])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### Correct Q5 columns values (bug in the form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "Change answer \"B)Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !\", in  \"D)Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_value = \"B)Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !\"\n",
    "new_value = \"D)Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !Hey ! Hey ! Hey ! Hey !\"\n",
    "\n",
    "# Count rows matching old value\n",
    "pre_test_impacted_lines = (pre_test_data[tes_const.Q5_KEY] == old_value).sum()\n",
    "post_test_impacted_lines = (post_test_data[tes_const.Q5_KEY] == old_value).sum()\n",
    "print(\"Pre-test impacted lines :\", pre_test_impacted_lines)\n",
    "print(\"Post-test impacted lines :\", post_test_impacted_lines)\n",
    "\n",
    "# Apply replacement\n",
    "pre_test_data[tes_const.Q5_KEY] = pre_test_data[tes_const.Q5_KEY].replace(old_value, new_value)\n",
    "post_test_data[tes_const.Q5_KEY] = post_test_data[tes_const.Q5_KEY].replace(old_value, new_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Merge the gender columns for group A and group B+C in post-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from student id to group id\n",
    "student_to_group_mapping = {}\n",
    "for student in stu_const.ALL_STUDENTS:\n",
    "    student_to_group_mapping[student[stu_const.STUDENT_ID]] = student[stu_const.GROUP_ID]\n",
    "\n",
    "# Function to get the correct gender value depending on the group\n",
    "def get_gender_value(row):\n",
    "    student_id = row[tes_const.STUDENT_ID_KEY]\n",
    "    group_id = student_to_group_mapping.get(student_id, None)\n",
    "\n",
    "    if group_id is None:\n",
    "        return None  # Student not kept in experimentation\n",
    "\n",
    "    if group_id == stu_const.GROUP_A:\n",
    "        return row[tes_const.QK_KEY]  # gender from QK for group A\n",
    "    else:\n",
    "        return row[tes_const.QH_KEY]  # gender from QH for groups B and C\n",
    "\n",
    "# Apply to post test\n",
    "post_test_data[tes_const.GENDER_KEY] = post_test_data.apply(get_gender_value, axis=1)\n",
    "# Delete QK and QH columns from post test\n",
    "post_test_data = post_test_data.drop(columns=[tes_const.QH_KEY,tes_const.QK_KEY], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Normalisation of gender column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "Normalization to `M`-`F`-`O`-`NA` (i.e., Male / Female / Other / No Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique values (strip and lower case) -> used to make lists below\n",
    "print(post_test_data[tes_const.GENDER_KEY].str.strip().str.lower().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "MALE_VALUES = [\"homme\",\"h\",\"masculin\",\"home\",\"m\",\"amsculin\",\"masculine\",\"garçon\",\"hgomme\"]\n",
    "FEMALE_VALUES = [\"femme\",\"fille\",\"f\",\"feminin\",\"féminin\",\"femelle\",\"je suis une femme\",\"femme ^-^\",\"fame\"]\n",
    "\n",
    "def mapping_function(gender_value):\n",
    "     # nan / None and empty value\n",
    "    if pd.isna(gender_value) or str(gender_value).strip() == \"\":\n",
    "        return tes_const.GENDER_NO_ANSWER  \n",
    "    gender_value_clean = str(gender_value).strip().lower()\n",
    "    if gender_value_clean in MALE_VALUES:\n",
    "        return tes_const.GENDER_MALE\n",
    "    elif gender_value_clean in FEMALE_VALUES:\n",
    "        return tes_const.GENDER_FEMALE\n",
    "    else:\n",
    "        return tes_const.GENDER_OTHER\n",
    "              \n",
    "post_test_data[tes_const.GENDER_KEY] = post_test_data[tes_const.GENDER_KEY].apply(mapping_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "print(post_test_data[tes_const.GENDER_KEY].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "### Simplifying Multiple-choice question answers in both pre and post-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to modify\n",
    "cols_to_trim = tes_const.PROGRAMMING_QUESTIONS\n",
    "# Keep only the first character of specified columns (i.e. A/B/C/D/E)\n",
    "pre_test_data[cols_to_trim] = pre_test_data[cols_to_trim].apply(lambda x: x.str[0])\n",
    "post_test_data[cols_to_trim] = post_test_data[cols_to_trim].apply(lambda x: x.str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "print(\"Pre-test :\")\n",
    "for question in tes_const.PROGRAMMING_QUESTIONS:\n",
    "    values = sorted(pre_test_data[question].dropna().unique())\n",
    "    print(f\"{question} : {values}\")\n",
    "print(\"\\nPost-test :\")\n",
    "for question in tes_const.PROGRAMMING_QUESTIONS:\n",
    "    values = sorted(post_test_data[question].dropna().unique())\n",
    "    print(f\"{question} : {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### Deletion of unsubmitted tests (creates outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of pre-test before delete: {len(pre_test_data)}\")\n",
    "deleted_pre_ids = pre_test_data.loc[pre_test_data[tes_const.T2_KEY].isna(), tes_const.STUDENT_ID_KEY].tolist()\n",
    "print(f\"Deleted pre-test student_ids: {deleted_pre_ids}\")\n",
    "pre_test_data = pre_test_data[pre_test_data[tes_const.T2_KEY].notna()]\n",
    "print(f\"Number of pre-test after delete: {len(pre_test_data)}\\n\")\n",
    "\n",
    "print(f\"Number of post-test before delete: {len(post_test_data)}\")\n",
    "deleted_post_ids = post_test_data.loc[post_test_data[tes_const.T2_KEY].isna(), tes_const.STUDENT_ID_KEY].tolist()\n",
    "print(f\"Deleted post-test student_ids: {deleted_post_ids}\")\n",
    "post_test_data = post_test_data[post_test_data[tes_const.T2_KEY].notna()]\n",
    "print(f\"Number of post-test after delete: {len(post_test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### Correction of student_id errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "Student 381 entered the wrong student_id during his post-test (entered 382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    post_test_data[tes_const.STUDENT_ID_KEY] == 382\n",
    ") & (\n",
    "    post_test_data[tes_const.T2_KEY] == pd.to_datetime(\"04/12/2025 09:41\",format=\"%d/%m/%Y %H:%M\")\n",
    ")\n",
    "\n",
    "print(\"Found matches :\", mask.sum())\n",
    "print(post_test_data.loc[mask, [tes_const.STUDENT_ID_KEY, tes_const.T2_KEY]])\n",
    "\n",
    "post_test_data.loc[mask, tes_const.STUDENT_ID_KEY] = 381"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "## 5/ Data filtration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### 5.1 / Interaction traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "### Check students activity outside the sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "We removed from the data students who progressed through a level outside of the sessions (see commented lines on `src/students_constants.py`). We kept students who performed other actions that did not lead to progression in a level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store first, last timestamps and count per student\n",
    "students_out_of_session = {}\n",
    "\n",
    "# Iterate over each class\n",
    "for class_name, sessions in ses_const.SESSION_DATE.items():\n",
    "    \n",
    "    if class_name in stu_const.CLASS_MAPPING:\n",
    "        class_students = [s[stu_const.GAME_ID] for s in stu_const.CLASS_MAPPING[class_name]]\n",
    "    else:\n",
    "        print(f\"Class {class_name} not found in class_mapping\")\n",
    "        continue\n",
    "    \n",
    "    # Create session intervals\n",
    "    session_intervals = [\n",
    "        (pd.to_datetime(s['start'], format=\"%Y-%m-%d %H:%M:%S.%f\"),\n",
    "         pd.to_datetime(s['end'],   format=\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "        for s in sessions.values()\n",
    "    ]\n",
    "    \n",
    "    # Filter traces for students in this class\n",
    "    class_traces = interaction_data[interaction_data[int_const.GAME_ID_DATA_KEY].isin(class_students)]\n",
    "    \n",
    "    # Check each trace\n",
    "    for idx, row in class_traces.iterrows():\n",
    "        trace_time = row[int_const.DATE_DATA_KEY]\n",
    "        trace_student = row[int_const.GAME_ID_DATA_KEY]\n",
    "        \n",
    "        # Check if trace_time is outside all sessions\n",
    "        if not any(start <= trace_time <= end for start, end in session_intervals):\n",
    "            if trace_student not in students_out_of_session:\n",
    "                # Initialize: first, last, count\n",
    "                students_out_of_session[trace_student] = [trace_time, trace_time, 1]\n",
    "            else:\n",
    "                # Update first, last and increment count\n",
    "                students_out_of_session[trace_student][0] = min(students_out_of_session[trace_student][0], trace_time)\n",
    "                students_out_of_session[trace_student][1] = max(students_out_of_session[trace_student][1], trace_time)\n",
    "                students_out_of_session[trace_student][2] += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"STUDENTS WITH TRACES OUTSIDE SESSIONS :\\n\")\n",
    "\n",
    "if students_out_of_session:\n",
    "    for game_id, (first_time, last_time, count) in sorted(students_out_of_session.items()):\n",
    "        print(f\"{game_id}: {count} traces out of session - first = {first_time}, last = {last_time}\")\n",
    "else:\n",
    "    print(\"No traces found outside sessions!\")\n",
    "\n",
    "print(f\"\\nTotal students with out-of-session traces: {len(students_out_of_session)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "###  Filtration of interaction traces on students and sessions dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of students in the study :\", len(stu_const.ALL_STUDENTS))\n",
    "print(\"Number of interaction traces initially :\", len(interaction_data))\n",
    "\n",
    "# Convert session dates to datetime\n",
    "for class_id, sessions in ses_const.SESSION_DATE.items():\n",
    "    for session_id, bounds in sessions.items():\n",
    "        bounds[\"start\"] = pd.to_datetime(bounds[\"start\"], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        bounds[\"end\"]   = pd.to_datetime(bounds[\"end\"],   format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "# New clean DataFrame for filtered interaction traces\n",
    "filtered_interaction = []\n",
    "\n",
    "# Process class by class\n",
    "for class_id, sessions in ses_const.SESSION_DATE.items():\n",
    "    # Get students in this class\n",
    "    class_students = [s[stu_const.GAME_ID] for s in stu_const.CLASS_MAPPING[class_id]]\n",
    "    # Get session intervals for this class\n",
    "    class_intervals = [\n",
    "        (bounds[\"start\"], bounds[\"end\"])\n",
    "        for bounds in sessions.values()\n",
    "    ]\n",
    "    # Extract only traces from these students\n",
    "    class_traces = interaction_data[\n",
    "        interaction_data[int_const.GAME_ID_DATA_KEY].isin(class_students)\n",
    "    ]\n",
    "    # Filter traces inside this class’s sessions\n",
    "    class_mask = False\n",
    "    for start, end in class_intervals:\n",
    "        class_mask |= class_traces[int_const.DATE_DATA_KEY].between(start, end)\n",
    "\n",
    "    valid_traces = class_traces.loc[class_mask]\n",
    "    # Append to global filtered dataset\n",
    "    filtered_interaction.append(valid_traces)\n",
    "\n",
    "# Concatenate all filtered traces\n",
    "interaction_data = pd.concat(filtered_interaction, ignore_index=True)\n",
    "\n",
    "print(\"Number of interaction traces after student and date filtration:\", len(interaction_data))\n",
    "\n",
    "# Summary per day\n",
    "traces_per_day = (\n",
    "    interaction_data\n",
    "        .groupby(interaction_data[int_const.DATE_DATA_KEY].dt.date)\n",
    "        .size()\n",
    "        .reset_index(name=\"nb_traces\")\n",
    "        .rename(columns={int_const.DATE_DATA_KEY: \"date\"})\n",
    ")\n",
    "\n",
    "print(\"Number of interaction traces by days:\")\n",
    "print(traces_per_day)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "### 5.2 / Pre and post-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "###  Filtration of pre and post-tests on students of the experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tests to keep only traces from valid students in our study\n",
    "valid_student_ids = [student[stu_const.STUDENT_ID] for student in stu_const.ALL_STUDENTS]\n",
    "pre_test_data = pre_test_data[\n",
    "    pre_test_data[tes_const.STUDENT_ID_KEY].isin(valid_student_ids)\n",
    "]\n",
    "post_test_data = post_test_data[\n",
    "    post_test_data[tes_const.STUDENT_ID_KEY].isin(valid_student_ids)\n",
    "]\n",
    "print(\"Number of students in pre-test :\", pre_test_data[tes_const.STUDENT_ID_KEY].nunique())\n",
    "print(\"Number of students in post-test:\", post_test_data[tes_const.STUDENT_ID_KEY].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "## 6/ Checkings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "### Check if students are missing in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Extract all expected student ids and game ids\n",
    "expected_student_ids = [student[stu_const.STUDENT_ID] for student in stu_const.ALL_STUDENTS]\n",
    "expected_game_ids = [student[stu_const.GAME_ID] for student in stu_const.ALL_STUDENTS]\n",
    "\n",
    "# Check presence in interaction traces\n",
    "students_with_interactions = interaction_data[int_const.GAME_ID_DATA_KEY].unique()\n",
    "missing_interactions = set(expected_game_ids) - set(students_with_interactions)\n",
    "print(\"=== Interaction traces check ===\")\n",
    "print(\"Expected game ids:\", len(expected_game_ids))\n",
    "print(\"Found in traces:\", len(students_with_interactions))\n",
    "print(\"Missing game ids:\")\n",
    "if missing_interactions:\n",
    "    print(sorted(missing_interactions))\n",
    "else:\n",
    "    print(\"No missing\")\n",
    "\n",
    "# Check presence in pre-test data\n",
    "students_in_pre = pre_test_data[tes_const.STUDENT_ID_KEY].unique()\n",
    "missing_pre = set(expected_student_ids) - set(students_in_pre)\n",
    "print(\"\\n=== Pre-test check ===\")\n",
    "print(\"Expected student ids:\", len(expected_student_ids))\n",
    "print(\"Found in pre-test:\", len(students_in_pre))\n",
    "print(\"Missing student ids:\")\n",
    "if missing_pre:\n",
    "    print(sorted(missing_pre))\n",
    "else:\n",
    "    print(\"No missing\")\n",
    "\n",
    "# Check presence in post-test data\n",
    "students_in_post = post_test_data[tes_const.STUDENT_ID_KEY].unique()\n",
    "missing_post = set(expected_student_ids) - set(students_in_post)\n",
    "print(\"\\n=== Post-test check ===\")\n",
    "print(\"Expected student ids:\", len(expected_student_ids))\n",
    "print(\"Found in post-test:\", len(students_in_post))\n",
    "print(\"Missing student ids:\")\n",
    "if missing_pre:\n",
    "    print(sorted(missing_post))\n",
    "else:\n",
    "    print(\"No missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "### Check of submission uniqueness in pre and post-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_pre = pre_test_data[tes_const.STUDENT_ID_KEY].value_counts()\n",
    "multi_pre = multi_pre[multi_pre > 1]\n",
    "\n",
    "print(\"Students with multiple submissions in pre-test:\")\n",
    "print(multi_pre.to_string() if not multi_pre.empty else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_post = post_test_data[tes_const.STUDENT_ID_KEY].value_counts()\n",
    "multi_post = multi_post[multi_post > 1]\n",
    "\n",
    "print(\"Students with multiple submissions in post-test:\")\n",
    "print(multi_post.to_string() if not multi_post.empty else \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "### Check that students are present on each sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "We removed from data students who were absent from at least one session (see commented lines on `src/students_constants.py`). Except if the student had completed the game and was not active in the next sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store students who missed at least one session\n",
    "students_with_absences = {}\n",
    "\n",
    "# Analyze attendance for each class\n",
    "for class_name, sessions in ses_const.SESSION_DATE.items():\n",
    "    print(f\"\\n=== {class_name} ===\")\n",
    "    \n",
    "    # Get student list for this class using the mapping\n",
    "    if class_name in stu_const.CLASS_MAPPING:\n",
    "        class_students = [s[stu_const.GAME_ID] for s in stu_const.CLASS_MAPPING[class_name]]\n",
    "    else:\n",
    "        print(f\"Class {class_name} not found in class_mapping\")\n",
    "        continue\n",
    "    \n",
    "    # Check each session\n",
    "    for session_name, session_times in sessions.items():\n",
    "        start_time = pd.to_datetime(session_times['start'], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        end_time = pd.to_datetime(session_times['end'],  format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        \n",
    "        # Filter traces for this session\n",
    "        session_traces = interaction_data[\n",
    "            (interaction_data[int_const.DATE_DATA_KEY] >= start_time) & \n",
    "            (interaction_data[int_const.DATE_DATA_KEY] <= end_time)\n",
    "        ]\n",
    "        \n",
    "        # Students present (with at least one activity)\n",
    "        present_students = set()\n",
    "        for game_id in session_traces[int_const.GAME_ID_DATA_KEY].unique():\n",
    "            present_students.add(game_id)\n",
    "        \n",
    "        # Students absent\n",
    "        absent_students = set(class_students) - present_students\n",
    "        \n",
    "        if absent_students:\n",
    "            print(f\"Session {session_name}: {len(absent_students)} absent(s) - {sorted(absent_students)}\")\n",
    "            \n",
    "            # Track students with absences\n",
    "            for game_id in absent_students:\n",
    "                if game_id not in students_with_absences:\n",
    "                    students_with_absences[game_id] = []\n",
    "                students_with_absences[game_id].append(f\"{class_name}_{session_name}\")\n",
    "        else:\n",
    "            print(f\"Session {session_name}: All students present\")\n",
    "\n",
    "# Display summary of students with absences\n",
    "print(\"\\n=== SUMMARY : STUDENT WHO MISSED AT LEAST ONE SESSION ===\")\n",
    "\n",
    "if students_with_absences:\n",
    "    for game_id, missed_sessions in sorted(students_with_absences.items()):\n",
    "        print(f\"{game_id}: missed {len(missed_sessions)} session(s) - {missed_sessions}\")\n",
    "else:\n",
    "    print(\"All students attended all sessions!\")\n",
    "\n",
    "print(f\"\\nTotal students with absences: {len(students_with_absences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "## 7/ Data enriching for futur splitting and filtration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "### Interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from game id to group id\n",
    "game_to_group_mapping = {}\n",
    "for student in stu_const.ALL_STUDENTS:\n",
    "    game_to_group_mapping[student[stu_const.GAME_ID]] = student[stu_const.GROUP_ID]\n",
    "\n",
    "# Create a mapping from game id to student id\n",
    "game_to_student_mapping = {}\n",
    "for student in stu_const.ALL_STUDENTS:\n",
    "    game_to_student_mapping[student[stu_const.GAME_ID]] = student[stu_const.STUDENT_ID]\n",
    "\n",
    "# Add group id and student id columns to the traces dataframe\n",
    "interaction_data[int_const.GROUP_ID_DATA_KEY] = interaction_data[int_const.GAME_ID_DATA_KEY].map(game_to_group_mapping)\n",
    "interaction_data[int_const.STUDENT_ID_DATA_KEY] = interaction_data[int_const.GAME_ID_DATA_KEY].map(game_to_student_mapping)\n",
    "\n",
    "# Count number of unique students per group\n",
    "students_per_group = interaction_data.groupby(int_const.GROUP_ID_DATA_KEY)[int_const.GAME_ID_DATA_KEY].nunique()\n",
    "print(\"\\n=== Number of students by group ===\")\n",
    "for group, count in students_per_group.items():\n",
    "    print(f\"Group {group}: {count} students\")\n",
    "print(f\"TOTAL: {students_per_group.sum()} students\")\n",
    "\n",
    "# Count traces per group\n",
    "traces_per_group = interaction_data[int_const.GROUP_ID_DATA_KEY].value_counts().sort_index()\n",
    "print(\"\\n=== Distribution of traces by group ===\")\n",
    "print(traces_per_group)\n",
    "print(f\"TOTAL: {traces_per_group.sum()} traces\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "### Pre and post-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from student id to group id\n",
    "student_to_group_mapping = {}\n",
    "for student in stu_const.ALL_STUDENTS:\n",
    "    student_to_group_mapping[student[stu_const.STUDENT_ID]] = student[stu_const.GROUP_ID]\n",
    "\n",
    "# Create a mapping from student id to game id\n",
    "student_to_game_mapping = {}\n",
    "for student in stu_const.ALL_STUDENTS:\n",
    "    student_to_game_mapping[student[stu_const.STUDENT_ID]] = student[stu_const.GAME_ID]\n",
    "\n",
    "# Add group id and game id columns to the tests dataframe\n",
    "pre_test_data[tes_const.GROUP_ID_KEY] = pre_test_data[tes_const.STUDENT_ID_KEY].map(student_to_group_mapping)\n",
    "pre_test_data[tes_const.GAME_ID_KEY] = pre_test_data[tes_const.STUDENT_ID_KEY].map(student_to_game_mapping)\n",
    "post_test_data[tes_const.GROUP_ID_KEY] = post_test_data[tes_const.STUDENT_ID_KEY].map(student_to_group_mapping)\n",
    "post_test_data[tes_const.GAME_ID_KEY] = post_test_data[tes_const.STUDENT_ID_KEY].map(student_to_game_mapping)\n",
    "\n",
    "# Count pre-test per group\n",
    "pre_test_per_group = pre_test_data[tes_const.GROUP_ID_KEY].value_counts().sort_index()\n",
    "print(\"\\n=== Distribution of pre-test by group ===\")\n",
    "print(pre_test_per_group)\n",
    "print(f\"TOTAL: {pre_test_per_group.sum()} pre-test\")\n",
    "\n",
    "# Count post-test per group\n",
    "post_test_per_group = post_test_data[tes_const.GROUP_ID_KEY].value_counts().sort_index()\n",
    "print(\"\\n=== Distribution of post-test by group ===\")\n",
    "print(post_test_per_group)\n",
    "print(f\"TOTAL: {post_test_per_group.sum()} post-test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "## 8/ Data exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel file for manual checking\n",
    "interaction_data.to_excel(\"../data/cleaned/cleaned_data_interaction_traces.xlsx\")\n",
    "pre_test_data.to_excel(\"../data/cleaned/cleaned_data_pre_test.xlsx\")\n",
    "post_test_data.to_excel(\"../data/cleaned/cleaned_data_post_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export du Pickle format for the following notebooks analyses\n",
    "interaction_data.to_pickle(\"../data/interim/interaction_data.pkl\")\n",
    "pre_test_data.to_pickle(\"../data/interim/pre_test_data.pkl\")\n",
    "post_test_data.to_pickle(\"../data/interim/post_test_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
